{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_niklaus.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "id": "mppKeZOQlJau",
        "outputId": "b3a0781f-e4c8-471a-92db-5b7a688f54b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp gdrive/My\\ Drive/*.npy .\n",
        "!cp gdrive/My\\ Drive/*.py .\n",
        "!ls -l"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 345.2MB 61kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.14.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (40.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (5.1.3)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.13.1\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "total 5395456\n",
            "-rw------- 1 root root       2875 Mar 27 11:46 _dataset_tools.py\n",
            "drwx------ 3 root root       4096 Mar 27 11:45 gdrive\n",
            "-rw------- 1 root root       2398 Mar 27 11:46 _my_tools.py\n",
            "drwxr-xr-x 1 root root       4096 Mar  8 17:26 sample_data\n",
            "-rw------- 1 root root  920825984 Mar 27 11:45 X_test.npy\n",
            "-rw------- 1 root root 2762440832 Mar 27 11:46 X_train.npy\n",
            "-rw------- 1 root root  460413056 Mar 27 11:46 y_test.npy\n",
            "-rw------- 1 root root 1381220480 Mar 27 11:46 y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JuEl6_bckw2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28600b71-30a5-4fd6-d7c5-22582e8c7500"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import _my_tools as mt\n",
        "import numpy as np\n",
        "\n",
        "X_train, y_train, X_test, y_test = mt.loadData(\"\",'float16',channels_last=True)\n",
        "\n",
        "print(\"tf version - \", tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version -  1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2IV3d8PqpBXk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "\n",
        "# It assumes, that we are using channel_last.\n",
        "class SepConv(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SepConv, self).__init__(**kwargs)\n",
        "        self.input_spec = [InputSpec(ndim=4), InputSpec(ndim=4),InputSpec(ndim=4)]\n",
        "\n",
        "        self.sess = tf.Session()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        assert (len(input_shape) == 3)\n",
        "\n",
        "        self.input_spec = [InputSpec(shape=input_shape[0]), InputSpec(shape=input_shape[1]), InputSpec(shape=input_shape[2])]\n",
        "        self.checkInput()\n",
        "\n",
        "    def call(self, x):\n",
        "        assert isinstance(x, list)\n",
        "        assert (len(x) == 3)\n",
        "        \n",
        "        # Unpack the batch dimension\n",
        "        output = tf.map_fn(self.l_1, x, dtype=tf.float32)\n",
        "        \n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        assert (len(input_shape) == 3)\n",
        "\n",
        "        img, horizontal, vertical = input_shape\n",
        "        \n",
        "        return [self.n_b, self.m_out, self.m_out, self.n_channels]\n",
        "\n",
        "    def checkInput(self):#, img, horizontal, vertical):\n",
        "        i_shape = self.input_spec[0].shape\n",
        "        h_shape = self.input_spec[1].shape\n",
        "        v_shape = self.input_spec[2].shape\n",
        "    \n",
        "        self.n_b = i_shape[0] # number of batches\n",
        "        self.m = i_shape[1] # dimension of image\n",
        "        self.n_channels = i_shape[3] # number of channels\n",
        "        self.filter_size = h_shape[3] # size of filter == depth of NN output\n",
        "        self.m_out = self.m - self.filter_size + 1\n",
        "        \n",
        "        assert i_shape[1] == i_shape[2]\n",
        "        assert h_shape[3] == v_shape[3]\n",
        "        assert h_shape[1] == h_shape[2] == v_shape[1] == v_shape[2] == self.m_out\n",
        "    \n",
        "#     def localSepConv(self, x):\n",
        "#         img, horizontal, vertical = x\n",
        "#         output = np.zeros([self.m_out, self.m_out, self.n_channels])\n",
        "        \n",
        "#         for row in range(self.m_out):\n",
        "#             for col in range(self.m_out):\n",
        "#                 sub_patch = img[row:row + self.filter_size, col:col + self.filter_size, :]\n",
        "# #                 print(sess.run(tf.shape(sub_patch)))\n",
        "#                 kernel_h = tf.reshape( horizontal[row,col,:] , [1,self.filter_size,self.n_channels] )\n",
        "# #                 print(sess.run(kernel_h))\n",
        "# #                 kernel_v = tf.transpose(vertical[row,col,:])\n",
        "#                 kernel_v = tf.reshape( vertical[row,col,:] , [self.filter_size,1,self.n_channels] )\n",
        "# #                 print(sess.run(kernel_v))\n",
        "# #                 print(sess.run( tf.shape(tf.reduce_sum(sub_patch * kernel_h * kernel_v,[0,1]) )))\n",
        "#                 output[row,col,:] = tf.reduce_sum(sub_patch * kernel_h * kernel_v,[0,1])#.eval(session=self.sess)\n",
        "                \n",
        "#         return tf.convert_to_tensor(output)\n",
        "    \n",
        "    # l_1() unpacks the 1st dimension\n",
        "    # r is list [0,1,...,filter size], we will cut out the subpatch of input image according to this list\n",
        "    def l_1(self, x):\n",
        "        img, horizontal, vertical = x\n",
        "        \n",
        "        r = tf.convert_to_tensor(list(range(self.m_out)))\n",
        "        \n",
        "        output = tf.map_fn(lambda x: self.l_2(img,x), [horizontal,vertical,r], dtype=tf.float32)\n",
        "        \n",
        "        return output\n",
        "        \n",
        "    # l_2() unpacks the 2nd dimension\n",
        "    # sub_patch_tmp is sub patch of input image according to 1st dimension\n",
        "    def l_2(self, img, x):\n",
        "        horizontal, vertical, i = x\n",
        "\n",
        "        sub_patch_tmp = img[i:i + self.filter_size,:,:]\n",
        "        r = tf.convert_to_tensor(list(range(self.m_out)))\n",
        "        \n",
        "        output = tf.map_fn(lambda x: self.l_3(sub_patch_tmp,x),[horizontal, vertical,r], dtype=tf.float32)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    # sub_patch is sub patch of input image according to 1st and 2nd dimension\n",
        "    # l_3() performs convolution on sub_patch and kernels obtained from unpacking of input tensors\n",
        "    def l_3(self, img, x):\n",
        "        horizontal, vertical, i = x\n",
        "        \n",
        "        sub_patch = img[:,i:i + self.filter_size,:]\n",
        "        kernel_h = tf.reshape(horizontal,[1, self.filter_size, 1])\n",
        "        kernel_v = tf.reshape(vertical, [self.filter_size, 1, 1])\n",
        "        \n",
        "        output = tf.reduce_sum(sub_patch * kernel_h * kernel_v, [0,1])\n",
        "        \n",
        "        return output\n",
        "    \n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class padRep(Layer):\n",
        "    \n",
        "    def __init__(self, im, depth, **kwargs):\n",
        "        super(padRep, self).__init__(**kwargs)\n",
        "        \n",
        "        self.im = im # image / channel from input, that we want to extract and pad\n",
        "        self.depth = depth # depth of padding on every side of input\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(padRep, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, x):\n",
        "        i = 1\n",
        "        d = self.depth\n",
        "        res = x[:,:,:,self.im:self.im + 1]\n",
        "        \n",
        "        while d > 0 :\n",
        "            if i <= d :\n",
        "                res = tf.pad(res, [[0,0],[i,i],[i,i],[0,0]], \"SYMMETRIC\")\n",
        "                d -= i\n",
        "            else:\n",
        "                res = tf.pad(res, [[0,0],[d,d],[d,d],[0,0]], \"SYMMETRIC\")\n",
        "                d -= d\n",
        "            i *= 2\n",
        "        \n",
        "        return res\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1] + 2 * self.depth, input_shape[2] + 2 * self.depth, 1)\n",
        "      \n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def convBlock(in_channels, out_channels, kernel, stride, padding, activation):\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation)\n",
        "    ], name='convBlock' + str(in_channels) + '_' + str(out_channels))\n",
        "\n",
        "def upsampleBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation):\n",
        "    return keras.models.Sequential([\n",
        "        upsample,\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation)\n",
        "    ], name='upsampleBlock' + str(in_channels) + '_' + str(out_channels))\n",
        "\n",
        "def kernelConvBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation, name=None):\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation),\n",
        "        upsample,\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation)\n",
        "    ], name=name)\n",
        "\n",
        "def pool(pool_size, padding):\n",
        "    return keras.layers.AveragePooling2D(pool_size, padding=padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "MF_ldWBG9npx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1345
        },
        "outputId": "b9e3d18e-77ec-4562-de50-2c172498b6b7"
      },
      "cell_type": "code",
      "source": [
        "KERNEL_SIZE = 51\n",
        "conv_setup = {\n",
        "    'kernel' : (3,3),\n",
        "    'stride' : (1,1),\n",
        "    'padding' : 'same',\n",
        "    'activation' : 'relu'\n",
        "}\n",
        "pooling_setup = {\n",
        "    'pool_size' : (2,2),\n",
        "    'padding' : 'same'\n",
        "}\n",
        "upsample_setup = {\n",
        "    'size' : (2,2),\n",
        "    'interpolation' : 'bilinear'\n",
        "}\n",
        "\n",
        "pooling_layer = keras.layers.AveragePooling2D(**pooling_setup)\n",
        "upsample_layer = keras.layers.UpSampling2D(**upsample_setup)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "input_img = keras.layers.Input((96,96,2))\n",
        "\n",
        "# compression\n",
        "\n",
        "x32 = convBlock(2, 32, **conv_setup)(input_img)\n",
        "x32_p = pool(**pooling_setup)(x32)\n",
        "x64 = convBlock(32, 64, **conv_setup)(x32_p)\n",
        "x64_p = pool(**pooling_setup)(x64)\n",
        "x128 = convBlock(64, 128, **conv_setup)(x64_p)\n",
        "x128_p = pool(**pooling_setup)(x128)\n",
        "x256 = convBlock(128, 256, **conv_setup)(x128_p)\n",
        "x256_p = pool(**pooling_setup)(x256)\n",
        "# x512 = convBlock(256, 512, **conv_setup)(x256_p)\n",
        "# x512_p = pool(**pooling_setup)(x512)\n",
        "\n",
        "# x = convBlock(512, 512, **conv_setup)(x512_p)\n",
        "\n",
        "x = convBlock(256, 256, **conv_setup)(x256_p)\n",
        "\n",
        "# expansion\n",
        "\n",
        "# x = upsampleBlock(upsample_layer, 512, 512, **conv_setup)(x)\n",
        "# x = keras.layers.Add()([x,x512])\n",
        "# x = convBlock(512, 256, **conv_setup)(x)\n",
        "\n",
        "x = upsampleBlock(upsample_layer, 256, 256, **conv_setup)(x)\n",
        "x = keras.layers.Add()([x,x256])\n",
        "x = convBlock(256, 128, **conv_setup)(x)\n",
        "\n",
        "x = upsampleBlock(upsample_layer, 128, 128, **conv_setup)(x)\n",
        "x = keras.layers.Add()([x,x128])\n",
        "x = convBlock(128, 64, **conv_setup)(x)\n",
        "\n",
        "x = upsampleBlock(upsample_layer, 64, 64, **conv_setup)(x)\n",
        "x = keras.layers.Add()([x,x64])\n",
        "\n",
        "# estimation of local convolution kernels\n",
        "\n",
        "k1h = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock1')(x)\n",
        "k1v = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock2')(x)\n",
        "k2h = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock3')(x)\n",
        "k2v = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock4')(x)\n",
        "\n",
        "im1 = padRep(0, KERNEL_SIZE//2)(input_img)\n",
        "im2 = padRep(1, KERNEL_SIZE//2)(input_img)\n",
        "\n",
        "out1 = SepConv()([im1,k1h,k1v])\n",
        "out2 = SepConv()([im2,k2h,k2v])\n",
        "\n",
        "output = keras.layers.Add()([out1,out2])\n",
        "\n",
        "model = keras.Model(input_img, output)\n",
        "model.compile(optimizer='adadelta', loss='mean_absolute_error')\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 96, 96, 2)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "convBlock2_32 (Sequential)      (None, 96, 96, 32)   684         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 48, 48, 32)   0           convBlock2_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "convBlock32_64 (Sequential)     (None, 48, 48, 64)   36992       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 24, 24, 64)   0           convBlock32_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "convBlock64_128 (Sequential)    (None, 24, 24, 128)  147712      average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 12, 12, 128)  0           convBlock64_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "convBlock128_256 (Sequential)   (None, 12, 12, 256)  590336      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 6, 6, 256)    0           convBlock128_256[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "convBlock256_256 (Sequential)   (None, 6, 6, 256)    1770240     average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "upsampleBlock256_256 (Sequentia (None, 12, 12, 256)  590080      convBlock256_256[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 12, 12, 256)  0           upsampleBlock256_256[0][0]       \n",
            "                                                                 convBlock128_256[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "convBlock256_128 (Sequential)   (None, 12, 12, 128)  1475200     add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "upsampleBlock128_128 (Sequentia (None, 24, 24, 128)  147584      convBlock256_128[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 24, 24, 128)  0           upsampleBlock128_128[0][0]       \n",
            "                                                                 convBlock64_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "convBlock128_64 (Sequential)    (None, 24, 24, 64)   368960      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "upsampleBlock64_64 (Sequential) (None, 48, 48, 64)   36928       convBlock128_64[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 48, 48, 64)   0           upsampleBlock64_64[0][0]         \n",
            "                                                                 convBlock32_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "pad_rep (padRep)                (None, 146, 146, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock1 (Sequential)   (None, 96, 96, 51)   126743      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock2 (Sequential)   (None, 96, 96, 51)   126743      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pad_rep_1 (padRep)              (None, 146, 146, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock3 (Sequential)   (None, 96, 96, 51)   126743      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock4 (Sequential)   (None, 96, 96, 51)   126743      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sep_conv (SepConv)              (None, 96, 96, 1)    0           pad_rep[0][0]                    \n",
            "                                                                 kernelConvBlock1[0][0]           \n",
            "                                                                 kernelConvBlock2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "sep_conv_1 (SepConv)            (None, 96, 96, 1)    0           pad_rep_1[0][0]                  \n",
            "                                                                 kernelConvBlock3[0][0]           \n",
            "                                                                 kernelConvBlock4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 96, 96, 1)    0           sep_conv[0][0]                   \n",
            "                                                                 sep_conv_1[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 5,671,688\n",
            "Trainable params: 5,671,688\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SVZCC0-gPbJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "2cf1f19c-4823-4069-dd66-40678c87fea3"
      },
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"10/cp\"\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                             save_weights_only=True,\n",
        "                                             verbose=1)\n",
        "csv_callback = keras.callbacks.CSVLogger('history', separator=',', append=True)\n",
        "\n",
        "batch_size = 16\n",
        "num_epoch = 1\n",
        "#model training\n",
        "model_log = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=num_epoch,\n",
        "          verbose=1,          \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks = [cp_callback, csv_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 149872 samples, validate on 49958 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQ5AVoWh9np2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Le test"
      ]
    },
    {
      "metadata": {
        "id": "wOLVJn0b9np3",
        "colab_type": "code",
        "colab": {},
        "outputId": "9fa97f61-0a59-4d5f-e4ff-52c8835f52e4"
      },
      "cell_type": "code",
      "source": [
        "L = SepConv()\n",
        "sess = tf.Session()\n",
        "L.build([[None,6,6,1],[None,4,4,3],[None,4,4,3]])\n",
        "\n",
        "A = tf.reshape(tf.constant([[0,0,1,2,3,3],[0,0,1,2,3,3],[1,1,2,3,4,4],[2,2,3.,4,5,5],[3,3,4,5,6,6],[3,3,4,5,6,6]]),[1,6,6,1])\n",
        "B = tf.reshape(tf.constant([[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]]]),[1,4,4,3])\n",
        "C = tf.reshape(tf.constant([[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]]]),[1,4,4,3])\n",
        "\n",
        "\n",
        "D = L.call([A,B,C])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[None, 6, 6, 1], [None, 4, 4, 3], [None, 4, 4, 3]]\n",
            "here -  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dhX36V8f9np7",
        "colab_type": "code",
        "colab": {},
        "outputId": "4889315c-e88d-4138-ced7-884e4a2016f8"
      },
      "cell_type": "code",
      "source": [
        "print(sess.run(tf.shape(D)))\n",
        "print(sess.run(D))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 4 4 1]\n",
            "[[[[3.]\n",
            "   [3.]\n",
            "   [3.]\n",
            "   [3.]]\n",
            "\n",
            "  [[6.]\n",
            "   [6.]\n",
            "   [6.]\n",
            "   [6.]]\n",
            "\n",
            "  [[6.]\n",
            "   [6.]\n",
            "   [6.]\n",
            "   [6.]]\n",
            "\n",
            "  [[3.]\n",
            "   [3.]\n",
            "   [3.]\n",
            "   [3.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kOydnrj_9np-",
        "colab_type": "code",
        "colab": {},
        "outputId": "6aa1da8f-0991-4a6d-8cf7-bd77cfb6e84e"
      },
      "cell_type": "code",
      "source": [
        "M = np.array([[0,1,2],[2,3,4],[4,5,6]]).reshape([1,3,3,1])\n",
        "x = model.predict(M)\n",
        "print(M.reshape([3,3]))\n",
        "print(x.reshape([9,9]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 2]\n",
            " [2 3 4]\n",
            " [4 5 6]]\n",
            "[[0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [2. 2. 2. 2. 3. 4. 4. 4. 4.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LSV4qHNo9nqC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}