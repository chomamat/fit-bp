{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mppKeZOQlJau",
    "outputId": "d36ae307-dfbb-44f8-fd7b-30f0806a5e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.6)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (2.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.14.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (40.8.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (5.1.3)\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "total 5395456\n",
      "-rw------- 1 root root       2875 Mar 21 14:18 _dataset_tools.py\n",
      "drwx------ 3 root root       4096 Mar 21 14:12 gdrive\n",
      "-rw------- 1 root root       2398 Mar 21 14:18 _my_tools.py\n",
      "drwxr-xr-x 1 root root       4096 Mar  8 17:26 sample_data\n",
      "-rw------- 1 root root  920825984 Mar 21 14:12 X_test.npy\n",
      "-rw------- 1 root root 2762440832 Mar 21 14:16 X_train.npy\n",
      "-rw------- 1 root root  460413056 Mar 21 14:17 y_test.npy\n",
      "-rw------- 1 root root 1381220480 Mar 21 14:18 y_train.npy\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!cp gdrive/My\\ Drive/*.npy .\n",
    "!cp gdrive/My\\ Drive/*.py .\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuEl6_bckw2t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version -  1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import _my_tools as mt\n",
    "import numpy as np\n",
    "\n",
    "# X_train, y_train, X_test, y_test = mt.loadData(\"\",'float16',channels_last=True)\n",
    "\n",
    "print(\"tf version - \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IV3d8PqpBXk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "\n",
    "# It assumes, that we are using channel_last.\n",
    "class SepConv(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SepConv, self).__init__(**kwargs)\n",
    "        self.input_spec = [InputSpec(ndim=4), InputSpec(ndim=4),InputSpec(ndim=4)]\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "#         self.input_spec = [InputSpec(ndim=4)]\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        assert (len(input_shape) == 3)\n",
    "        print(input_shape)\n",
    "        self.input_spec = [InputSpec(shape=input_shape[0]), InputSpec(shape=input_shape[1]), InputSpec(shape=input_shape[2])]\n",
    "#         print(self.input_spec[0].shape)\n",
    "        self.checkInput()\n",
    "#         super(SepConv, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        assert isinstance(x, list)\n",
    "        assert (len(x) == 3)\n",
    "        \n",
    "#         print(img)\n",
    "#         c = K.shape(x[0])\n",
    "#         print(\"A\",self.m_out)\n",
    "#         output = np.zeros([1, self.m_out, self.m_out, self.n_channels])\n",
    "#         print(\"out - \",output.shape)\n",
    "#         print(output[0,0,0,:])\n",
    "#         print(\"B\")\n",
    "#         output = tf.map_fn(lSC,[])\n",
    "#         for b in range(self.n_b): # now it's not paralelized. It will be probably slow.\n",
    "#             self.localSepConv(img[b],horizontal[b],vertical[b],output=output[b])\n",
    "        \n",
    "        output = tf.map_fn(self.l_1, x, dtype=tf.float32)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        assert (len(input_shape) == 3)\n",
    "\n",
    "        img, horizontal, vertical = input_shape\n",
    "#         self.checkInput()\n",
    "        \n",
    "        return [self.n_b, self.m_out, self.m_out, self.n_channels]\n",
    "\n",
    "    def checkInput(self):#, img, horizontal, vertical):\n",
    "#         i_shape = keras.backend.shape(img)\n",
    "#         h_shape = keras.backend.shape(horizontal)\n",
    "#         v_shape = keras.backend.shape(vertical)\n",
    "        \n",
    "        i_shape = self.input_spec[0].shape\n",
    "        h_shape = self.input_spec[1].shape\n",
    "        v_shape = self.input_spec[2].shape\n",
    "    \n",
    "        self.n_b = i_shape[0] # number of batches\n",
    "        self.m = i_shape[1] # dimension of image\n",
    "        self.n_channels = i_shape[3] # number of channels\n",
    "        self.filter_size = h_shape[3] # size of filter == depth of NN output\n",
    "        self.m_out = self.m - self.filter_size + 1\n",
    "        \n",
    "        print(\"here - \",i_shape[1])\n",
    "        \n",
    "#         tf.assert_equal(i_shape[1],i_shape[2])\n",
    "        assert i_shape[1] == i_shape[2]\n",
    "        assert h_shape[3] == v_shape[3]\n",
    "        assert h_shape[1] == h_shape[2] == v_shape[1] == v_shape[2] == self.m_out\n",
    "    \n",
    "    def localSepConv(self, x):\n",
    "        img, horizontal, vertical = x\n",
    "        output = np.zeros([self.m_out, self.m_out, self.n_channels])\n",
    "        \n",
    "        for row in range(self.m_out):\n",
    "            for col in range(self.m_out):\n",
    "                sub_patch = img[row:row + self.filter_size, col:col + self.filter_size, :]\n",
    "#                 print(sess.run(tf.shape(sub_patch)))\n",
    "                kernel_h = tf.reshape( horizontal[row,col,:] , [1,self.filter_size,self.n_channels] )\n",
    "#                 print(sess.run(kernel_h))\n",
    "#                 kernel_v = tf.transpose(vertical[row,col,:])\n",
    "                kernel_v = tf.reshape( vertical[row,col,:] , [self.filter_size,1,self.n_channels] )\n",
    "#                 print(sess.run(kernel_v))\n",
    "#                 print(sess.run( tf.shape(tf.reduce_sum(sub_patch * kernel_h * kernel_v,[0,1]) )))\n",
    "                output[row,col,:] = tf.reduce_sum(sub_patch * kernel_h * kernel_v,[0,1])#.eval(session=self.sess)\n",
    "                \n",
    "        return tf.convert_to_tensor(output)\n",
    "    \n",
    "    def l_1(self, x):\n",
    "        img, horizontal, vertical = x\n",
    "        \n",
    "        r = tf.convert_to_tensor(list(range(self.m_out)))\n",
    "        \n",
    "        output = tf.map_fn(lambda x: self.l_2(img,x), [horizontal,vertical,r], dtype=tf.float32)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def l_2(self, img, x):\n",
    "        horizontal, vertical, i = x\n",
    "\n",
    "        r = tf.convert_to_tensor(list(range(self.m_out)))\n",
    "        \n",
    "        output = tf.map_fn(lambda x: self.l_3(img[i:i + self.filter_size,:,:],x),[horizontal, vertical,r], dtype=tf.float32)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def l_3(self, img, x):\n",
    "        horizontal, vertical, i = x\n",
    "        \n",
    "        sub_patch = img[:,i:i + self.filter_size,:]\n",
    "        kernel_h = tf.reshape(horizontal,[1, self.filter_size, 1])\n",
    "        kernel_v = tf.reshape(vertical, [self.filter_size, 1, 1])\n",
    "        \n",
    "        output = tf.reduce_sum(sub_patch * kernel_h * kernel_v, [0,1])\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class padRep(Layer):\n",
    "    \n",
    "    def __init__(self, im, depth, **kwargs):\n",
    "        super(padRep, self).__init__(**kwargs)\n",
    "        \n",
    "        self.im = im # image / channel from input, that we want to extract and pad\n",
    "        self.depth = depth # depth of padding on every side of input\n",
    "        #         self.sess = tf.Session()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(padRep, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        i = 1\n",
    "        d = self.depth\n",
    "        res = x[:,:,:,self.im:self.im + 1]\n",
    "        \n",
    "        while d > 0 :\n",
    "            if i <= d :\n",
    "                res = tf.pad(res, [[0,0],[i,i],[i,i],[0,0]], \"SYMMETRIC\")\n",
    "                d -= i\n",
    "            else:\n",
    "                res = tf.pad(res, [[0,0],[d,d],[d,d],[0,0]], \"SYMMETRIC\")\n",
    "                d -= d\n",
    "            i *= 2\n",
    "        \n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] + 2 * self.depth, input_shape[2] + 2 * self.depth, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([Dimension(None), Dimension(146), Dimension(146), Dimension(1)]), TensorShape([Dimension(None), Dimension(96), Dimension(96), Dimension(51)]), TensorShape([Dimension(None), Dimension(96), Dimension(96), Dimension(51)])]\n",
      "here -  146\n",
      "[TensorShape([Dimension(None), Dimension(146), Dimension(146), Dimension(1)]), TensorShape([Dimension(None), Dimension(96), Dimension(96), Dimension(51)]), TensorShape([Dimension(None), Dimension(96), Dimension(96), Dimension(51)])]\n",
      "here -  146\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 96, 96, 2)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 96, 96, 32)   608         input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 48, 48, 32)   0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 48, 48, 64)   18496       average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 96, 96, 64)   0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 96, 96, 32)   18464       up_sampling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pad_rep_30 (padRep)             (None, 146, 146, 1)  0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 96, 96, 51)   14739       conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 96, 96, 51)   14739       conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pad_rep_31 (padRep)             (None, 146, 146, 1)  0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 96, 96, 51)   14739       conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 96, 96, 51)   14739       conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_24 (SepConv)           (None, 96, 96, 1)    0           pad_rep_30[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sep_conv_25 (SepConv)           (None, 96, 96, 1)    0           pad_rep_31[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 96, 96, 1)    0           sep_conv_24[0][0]                \n",
      "                                                                 sep_conv_25[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 96,524\n",
      "Trainable params: 96,524\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_size = 51\n",
    "\n",
    "input_img = keras.layers.Input((96,96,2))\n",
    "\n",
    "x32 = keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(input_img)\n",
    "x32 = keras.layers.AveragePooling2D((2,2),padding='same')(x32)\n",
    "\n",
    "x64 = keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')(x32)\n",
    "x = keras.layers.UpSampling2D((2, 2), interpolation='bilinear')(x64)\n",
    "x = keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n",
    "\n",
    "k1h = keras.layers.Conv2D(filter_size,(3,3),activation='relu',padding='same')(x)\n",
    "k1v = keras.layers.Conv2D(filter_size,(3,3),activation='relu',padding='same')(x)\n",
    "k2h = keras.layers.Conv2D(filter_size,(3,3),activation='relu',padding='same')(x)\n",
    "k2v = keras.layers.Conv2D(filter_size,(3,3),activation='relu',padding='same')(x)\n",
    "\n",
    "im1 = padRep(0, filter_size//2)(input_img)\n",
    "im2 = padRep(1, filter_size//2)(input_img)\n",
    "\n",
    "out1 = SepConv()([im1,k1h,k1v])\n",
    "out2 = SepConv()([im2,k2h,k2v])\n",
    "\n",
    "output = keras.layers.Add()([out1,out2])\n",
    "\n",
    "model = keras.Model(input_img, output)\n",
    "model.compile(optimizer='adadelta', loss='mean_absolute_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, 6, 6, 1], [None, 4, 4, 3], [None, 4, 4, 3]]\n",
      "here -  6\n"
     ]
    }
   ],
   "source": [
    "L = SepConv()\n",
    "sess = tf.Session()\n",
    "L.build([[None,6,6,1],[None,4,4,3],[None,4,4,3]])\n",
    "\n",
    "A = tf.reshape(tf.constant([[0,0,1,2,3,3],[0,0,1,2,3,3],[1,1,2,3,4,4],[2,2,3.,4,5,5],[3,3,4,5,6,6],[3,3,4,5,6,6]]),[1,6,6,1])\n",
    "B = tf.reshape(tf.constant([[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]]]),[1,4,4,3])\n",
    "C = tf.reshape(tf.constant([[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]]]),[1,4,4,3])\n",
    "\n",
    "\n",
    "D = L.call([A,B,C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 4 1]\n",
      "[[[[3.]\n",
      "   [3.]\n",
      "   [3.]\n",
      "   [3.]]\n",
      "\n",
      "  [[6.]\n",
      "   [6.]\n",
      "   [6.]\n",
      "   [6.]]\n",
      "\n",
      "  [[6.]\n",
      "   [6.]\n",
      "   [6.]\n",
      "   [6.]]\n",
      "\n",
      "  [[3.]\n",
      "   [3.]\n",
      "   [3.]\n",
      "   [3.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.shape(D)))\n",
    "print(sess.run(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [2 3 4]\n",
      " [4 5 6]]\n",
      "[[0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
      " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
      " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
      " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 3. 4. 4. 4. 4.]\n",
      " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
      " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
      " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
      " [4. 4. 4. 4. 5. 6. 6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "M = np.array([[0,1,2],[2,3,4],[4,5,6]]).reshape([1,3,3,1])\n",
    "x = model.predict(M)\n",
    "print(M.reshape([3,3]))\n",
    "print(x.reshape([9,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "10_niklaus.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
