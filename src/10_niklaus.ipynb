{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_niklaus.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "id": "mppKeZOQlJau",
        "outputId": "de57c46f-0f21-4f6a-c86f-995852385384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!mkdir -p x64\n",
        "!cp gdrive/My\\ Drive/x64/*.npy x64/.\n",
        "!cp gdrive/My\\ Drive/*.py .\n",
        "!ls -l"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.6)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (40.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (5.1.3)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "total 5395780\n",
            "-rw------- 1 root root       2875 Mar 27 13:32 _dataset_tools.py\n",
            "drwx------ 3 root root       4096 Mar 27 11:45 gdrive\n",
            "-rw-r--r-- 1 root root          0 Mar 27 13:13 history\n",
            "-rw-r--r-- 1 root root     319586 Mar 27 13:19 model.png\n",
            "-rw------- 1 root root       2398 Mar 27 13:32 _my_tools.py\n",
            "drwxr-xr-x 2 root root       4096 Mar 27 11:47 __pycache__\n",
            "drwxr-xr-x 1 root root       4096 Mar  8 17:26 sample_data\n",
            "drwxr-xr-x 2 root root       4096 Mar 27 13:32 x64\n",
            "-rw------- 1 root root  920825984 Mar 27 11:45 X_test.npy\n",
            "-rw------- 1 root root 2762440832 Mar 27 11:46 X_train.npy\n",
            "-rw------- 1 root root  460413056 Mar 27 11:46 y_test.npy\n",
            "-rw------- 1 root root 1381220480 Mar 27 11:46 y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JuEl6_bckw2t",
        "outputId": "fd9b54bd-46f3-47a5-9367-df8447239a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import _my_tools as mt\n",
        "import numpy as np\n",
        "\n",
        "X_train, y_train, X_test, y_test = mt.loadData(\"x64/\",'float16',channels_last=True)\n",
        "\n",
        "print(\"tf version - \", tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version -  1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2IV3d8PqpBXk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "\n",
        "# It assumes, that we are using channel_last.\n",
        "class SepConv(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SepConv, self).__init__(**kwargs)\n",
        "        self.input_spec = [InputSpec(ndim=4), InputSpec(ndim=4),InputSpec(ndim=4)]\n",
        "\n",
        "        self.sess = tf.Session()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        assert (len(input_shape) == 3)\n",
        "\n",
        "        self.input_spec = [InputSpec(shape=input_shape[0]), InputSpec(shape=input_shape[1]), InputSpec(shape=input_shape[2])]\n",
        "        self.checkInput()\n",
        "\n",
        "    def call(self, x):\n",
        "        assert isinstance(x, list)\n",
        "        assert (len(x) == 3)\n",
        "        \n",
        "        # Unpack the batch dimension\n",
        "        output = tf.map_fn(self.l_1, x, dtype=tf.float32)\n",
        "        \n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        assert (len(input_shape) == 3)\n",
        "\n",
        "        img, horizontal, vertical = input_shape\n",
        "        \n",
        "        return [self.n_b, self.m_out, self.m_out, self.n_channels]\n",
        "\n",
        "    def checkInput(self):#, img, horizontal, vertical):\n",
        "        i_shape = self.input_spec[0].shape\n",
        "        h_shape = self.input_spec[1].shape\n",
        "        v_shape = self.input_spec[2].shape\n",
        "    \n",
        "        self.n_b = i_shape[0] # number of batches\n",
        "        self.m = i_shape[1] # dimension of image\n",
        "        self.n_channels = i_shape[3] # number of channels\n",
        "        self.filter_size = h_shape[3] # size of filter == depth of NN output\n",
        "        self.m_out = self.m - self.filter_size + 1\n",
        "        \n",
        "        assert i_shape[1] == i_shape[2]\n",
        "        assert h_shape[3] == v_shape[3]\n",
        "        assert h_shape[1] == h_shape[2] == v_shape[1] == v_shape[2] == self.m_out\n",
        "    \n",
        "#     def localSepConv(self, x):\n",
        "#         img, horizontal, vertical = x\n",
        "#         output = np.zeros([self.m_out, self.m_out, self.n_channels])\n",
        "        \n",
        "#         for row in range(self.m_out):\n",
        "#             for col in range(self.m_out):\n",
        "#                 sub_patch = img[row:row + self.filter_size, col:col + self.filter_size, :]\n",
        "# #                 print(sess.run(tf.shape(sub_patch)))\n",
        "#                 kernel_h = tf.reshape( horizontal[row,col,:] , [1,self.filter_size,self.n_channels] )\n",
        "# #                 print(sess.run(kernel_h))\n",
        "# #                 kernel_v = tf.transpose(vertical[row,col,:])\n",
        "#                 kernel_v = tf.reshape( vertical[row,col,:] , [self.filter_size,1,self.n_channels] )\n",
        "# #                 print(sess.run(kernel_v))\n",
        "# #                 print(sess.run( tf.shape(tf.reduce_sum(sub_patch * kernel_h * kernel_v,[0,1]) )))\n",
        "#                 output[row,col,:] = tf.reduce_sum(sub_patch * kernel_h * kernel_v,[0,1])#.eval(session=self.sess)\n",
        "                \n",
        "#         return tf.convert_to_tensor(output)\n",
        "    \n",
        "    # l_1() unpacks the 1st dimension\n",
        "    # r is list [0,1,...,filter size], we will cut out the subpatch of input image according to this list\n",
        "    def l_1(self, x):\n",
        "        img, horizontal, vertical = x\n",
        "        \n",
        "        r = tf.convert_to_tensor(list(range(self.m_out)))\n",
        "        \n",
        "        output = tf.map_fn(lambda x: self.l_2(img,x), [horizontal,vertical,r], dtype=tf.float32)\n",
        "        \n",
        "        return output\n",
        "        \n",
        "    # l_2() unpacks the 2nd dimension\n",
        "    # sub_patch_tmp is sub patch of input image according to 1st dimension\n",
        "    def l_2(self, img, x):\n",
        "        horizontal, vertical, i = x\n",
        "\n",
        "        sub_patch_tmp = img[i:i + self.filter_size,:,:]\n",
        "        r = tf.convert_to_tensor(list(range(self.m_out)))\n",
        "        \n",
        "        output = tf.map_fn(lambda x: self.l_3(sub_patch_tmp,x),[horizontal, vertical,r], dtype=tf.float32)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    # sub_patch is sub patch of input image according to 1st and 2nd dimension\n",
        "    # l_3() performs convolution on sub_patch and kernels obtained from unpacking of input tensors\n",
        "    def l_3(self, img, x):\n",
        "        horizontal, vertical, i = x\n",
        "        \n",
        "        sub_patch = img[:,i:i + self.filter_size,:]\n",
        "        kernel_h = tf.reshape(horizontal,[1, self.filter_size, 1])\n",
        "        kernel_v = tf.reshape(vertical, [self.filter_size, 1, 1])\n",
        "        \n",
        "        output = tf.reduce_sum(sub_patch * kernel_h * kernel_v, [0,1])\n",
        "        \n",
        "        return output\n",
        "    \n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "class padRep(Layer):\n",
        "    \n",
        "    def __init__(self, im, depth, **kwargs):\n",
        "        super(padRep, self).__init__(**kwargs)\n",
        "        \n",
        "        self.im = im # image / channel from input, that we want to extract and pad\n",
        "        self.depth = depth # depth of padding on every side of input\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(padRep, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, x):\n",
        "        i = 1\n",
        "        d = self.depth\n",
        "        res = x[:,:,:,self.im:self.im + 1]\n",
        "        \n",
        "        while d > 0 :\n",
        "            if i <= d :\n",
        "                res = tf.pad(res, [[0,0],[i,i],[i,i],[0,0]], \"SYMMETRIC\")\n",
        "                d -= i\n",
        "            else:\n",
        "                res = tf.pad(res, [[0,0],[d,d],[d,d],[0,0]], \"SYMMETRIC\")\n",
        "                d -= d\n",
        "            i *= 2\n",
        "        \n",
        "        return res\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1] + 2 * self.depth, input_shape[2] + 2 * self.depth, 1)\n",
        "      \n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def convBlock(in_channels, out_channels, kernel, stride, padding, activation):\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation)\n",
        "    ], name='convBlock' + str(in_channels) + '_' + str(out_channels))\n",
        "\n",
        "def upsampleBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation):\n",
        "    return keras.models.Sequential([\n",
        "        upsample,\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation)\n",
        "    ], name='upsampleBlock' + str(in_channels) + '_' + str(out_channels))\n",
        "\n",
        "def kernelConvBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation, name=None):\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(in_channels, kernel, stride, padding, activation=activation),\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation),\n",
        "        upsample,\n",
        "        keras.layers.Conv2D(out_channels, kernel, stride, padding, activation=activation)\n",
        "    ], name=name)\n",
        "\n",
        "def pool(pool_size, padding):\n",
        "    return keras.layers.AveragePooling2D(pool_size, padding=padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "MF_ldWBG9npx",
        "colab_type": "code",
        "outputId": "7f410a65-d672-4943-f989-a212c0fd2845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1345
        }
      },
      "cell_type": "code",
      "source": [
        "KERNEL_SIZE = 31\n",
        "conv_setup = {\n",
        "    'kernel' : (3,3),\n",
        "    'stride' : (1,1),\n",
        "    'padding' : 'same',\n",
        "    'activation' : 'relu'\n",
        "}\n",
        "pooling_setup = {\n",
        "    'pool_size' : (2,2),\n",
        "    'padding' : 'same'\n",
        "}\n",
        "upsample_setup = {\n",
        "    'size' : (2,2),\n",
        "    'interpolation' : 'bilinear'\n",
        "}\n",
        "\n",
        "pooling_layer = keras.layers.AveragePooling2D(**pooling_setup)\n",
        "upsample_layer = keras.layers.UpSampling2D(**upsample_setup)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "input_img = keras.layers.Input((64,64,2))\n",
        "\n",
        "# compression\n",
        "\n",
        "x32 = convBlock(2, 32, **conv_setup)(input_img)\n",
        "x32_p = pool(**pooling_setup)(x32)\n",
        "x64 = convBlock(32, 64, **conv_setup)(x32_p)\n",
        "x64_p = pool(**pooling_setup)(x64)\n",
        "x128 = convBlock(64, 128, **conv_setup)(x64_p)\n",
        "x128_p = pool(**pooling_setup)(x128)\n",
        "x256 = convBlock(128, 256, **conv_setup)(x128_p)\n",
        "x256_p = pool(**pooling_setup)(x256)\n",
        "# x512 = convBlock(256, 512, **conv_setup)(x256_p)\n",
        "# x512_p = pool(**pooling_setup)(x512)\n",
        "\n",
        "# x = convBlock(512, 512, **conv_setup)(x512_p)\n",
        "\n",
        "x = convBlock(256, 256, **conv_setup)(x256_p)\n",
        "\n",
        "# expansion\n",
        "\n",
        "# x = upsampleBlock(upsample_layer, 512, 512, **conv_setup)(x)\n",
        "# x = keras.layers.Add()([x,x512])\n",
        "# x = convBlock(512, 256, **conv_setup)(x)\n",
        "\n",
        "x = upsampleBlock(upsample_layer, 256, 256, **conv_setup)(x)\n",
        "x = keras.layers.Add()([x,x256])\n",
        "x = convBlock(256, 128, **conv_setup)(x)\n",
        "\n",
        "x = upsampleBlock(upsample_layer, 128, 128, **conv_setup)(x)\n",
        "x = keras.layers.Add()([x,x128])\n",
        "x = convBlock(128, 64, **conv_setup)(x)\n",
        "\n",
        "x = upsampleBlock(upsample_layer, 64, 64, **conv_setup)(x)\n",
        "x = keras.layers.Add()([x,x64])\n",
        "\n",
        "# estimation of local convolution kernels\n",
        "\n",
        "k1h = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock1')(x)\n",
        "k1v = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock2')(x)\n",
        "k2h = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock3')(x)\n",
        "k2v = kernelConvBlock(upsample_layer, 64, KERNEL_SIZE, **conv_setup, name='kernelConvBlock4')(x)\n",
        "\n",
        "im1 = padRep(0, KERNEL_SIZE//2)(input_img)\n",
        "im2 = padRep(1, KERNEL_SIZE//2)(input_img)\n",
        "\n",
        "out1 = SepConv()([im1,k1h,k1v])\n",
        "out2 = SepConv()([im2,k2h,k2v])\n",
        "\n",
        "output = keras.layers.Add()([out1,out2])\n",
        "\n",
        "model = keras.Model(input_img, output)\n",
        "model.compile(optimizer='adadelta', loss='mean_absolute_error')\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 2)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "convBlock2_32 (Sequential)      (None, 64, 64, 32)   684         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 32, 32, 32)   0           convBlock2_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "convBlock32_64 (Sequential)     (None, 32, 32, 64)   36992       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 64)   0           convBlock32_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "convBlock64_128 (Sequential)    (None, 16, 16, 128)  147712      average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 8, 8, 128)    0           convBlock64_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "convBlock128_256 (Sequential)   (None, 8, 8, 256)    590336      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 4, 4, 256)    0           convBlock128_256[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "convBlock256_256 (Sequential)   (None, 4, 4, 256)    1770240     average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "upsampleBlock256_256 (Sequentia (None, 8, 8, 256)    590080      convBlock256_256[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 8, 8, 256)    0           upsampleBlock256_256[0][0]       \n",
            "                                                                 convBlock128_256[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "convBlock256_128 (Sequential)   (None, 8, 8, 128)    1475200     add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "upsampleBlock128_128 (Sequentia (None, 16, 16, 128)  147584      convBlock256_128[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 128)  0           upsampleBlock128_128[0][0]       \n",
            "                                                                 convBlock64_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "convBlock128_64 (Sequential)    (None, 16, 16, 64)   368960      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "upsampleBlock64_64 (Sequential) (None, 32, 32, 64)   36928       convBlock128_64[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           upsampleBlock64_64[0][0]         \n",
            "                                                                 convBlock32_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "pad_rep (padRep)                (None, 94, 94, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock1 (Sequential)   (None, 64, 64, 31)   100423      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock2 (Sequential)   (None, 64, 64, 31)   100423      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pad_rep_1 (padRep)              (None, 94, 94, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock3 (Sequential)   (None, 64, 64, 31)   100423      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "kernelConvBlock4 (Sequential)   (None, 64, 64, 31)   100423      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sep_conv (SepConv)              (None, 64, 64, 1)    0           pad_rep[0][0]                    \n",
            "                                                                 kernelConvBlock1[0][0]           \n",
            "                                                                 kernelConvBlock2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "sep_conv_1 (SepConv)            (None, 64, 64, 1)    0           pad_rep_1[0][0]                  \n",
            "                                                                 kernelConvBlock3[0][0]           \n",
            "                                                                 kernelConvBlock4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 64, 1)    0           sep_conv[0][0]                   \n",
            "                                                                 sep_conv_1[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 5,566,408\n",
            "Trainable params: 5,566,408\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2DV_Q6BoYbwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = model.predict(X_train[0:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgzAN2FFYmIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "8b71eb34-b11f-4f4c-c23f-f667bfe382e3"
      },
      "cell_type": "code",
      "source": [
        "mt.compare(0, X_train, y_train, a)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABqoAAAHCCAYAAACXE5hCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLPEX9D95AnZJuecAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 2160x2160 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SVZCC0-gPbJv",
        "colab_type": "code",
        "outputId": "be2e208c-78fd-4514-c696-cebb81a5a07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"10/cp\"\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                             save_weights_only=True,\n",
        "                                             verbose=1)\n",
        "csv_callback = keras.callbacks.CSVLogger('history', separator=',', append=True)\n",
        "\n",
        "batch_size = 16\n",
        "num_epoch = 1\n",
        "#model training\n",
        "model_log = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=num_epoch,\n",
        "          verbose=1,          \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks = [cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 63324 samples, validate on 15831 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQ5AVoWh9np2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Le test"
      ]
    },
    {
      "metadata": {
        "id": "wOLVJn0b9np3",
        "colab_type": "code",
        "outputId": "9fa97f61-0a59-4d5f-e4ff-52c8835f52e4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "L = SepConv()\n",
        "sess = tf.Session()\n",
        "L.build([[None,6,6,1],[None,4,4,3],[None,4,4,3]])\n",
        "\n",
        "A = tf.reshape(tf.constant([[0,0,1,2,3,3],[0,0,1,2,3,3],[1,1,2,3,4,4],[2,2,3.,4,5,5],[3,3,4,5,6,6],[3,3,4,5,6,6]]),[1,6,6,1])\n",
        "B = tf.reshape(tf.constant([[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]],[[0.,1,2],[0.,1,2],[0.,1,2],[0.,1,2]]]),[1,4,4,3])\n",
        "C = tf.reshape(tf.constant([[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]],[[-1.,0,1],[-1.,0,1],[-1.,0,1],[-1.,0,1]]]),[1,4,4,3])\n",
        "\n",
        "\n",
        "D = L.call([A,B,C])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[None, 6, 6, 1], [None, 4, 4, 3], [None, 4, 4, 3]]\n",
            "here -  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dhX36V8f9np7",
        "colab_type": "code",
        "outputId": "4889315c-e88d-4138-ced7-884e4a2016f8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(sess.run(tf.shape(D)))\n",
        "print(sess.run(D))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 4 4 1]\n",
            "[[[[3.]\n",
            "   [3.]\n",
            "   [3.]\n",
            "   [3.]]\n",
            "\n",
            "  [[6.]\n",
            "   [6.]\n",
            "   [6.]\n",
            "   [6.]]\n",
            "\n",
            "  [[6.]\n",
            "   [6.]\n",
            "   [6.]\n",
            "   [6.]]\n",
            "\n",
            "  [[3.]\n",
            "   [3.]\n",
            "   [3.]\n",
            "   [3.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kOydnrj_9np-",
        "colab_type": "code",
        "outputId": "6aa1da8f-0991-4a6d-8cf7-bd77cfb6e84e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "M = np.array([[0,1,2],[2,3,4],[4,5,6]]).reshape([1,3,3,1])\n",
        "x = model.predict(M)\n",
        "print(M.reshape([3,3]))\n",
        "print(x.reshape([9,9]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 2]\n",
            " [2 3 4]\n",
            " [4 5 6]]\n",
            "[[0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [0. 0. 0. 0. 1. 2. 2. 2. 2.]\n",
            " [2. 2. 2. 2. 3. 4. 4. 4. 4.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]\n",
            " [4. 4. 4. 4. 5. 6. 6. 6. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LSV4qHNo9nqC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}