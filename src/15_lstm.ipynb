{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_lstm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "atLFwjkUSqRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "c98d0b82-f039-44ed-a167-20db53dc2cd6"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp -r gdrive/My\\ Drive/tools/ .\n",
        "!ls -l"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "total 12\n",
            "drwx------ 3 root root 4096 Apr 30 22:09 gdrive\n",
            "drwxr-xr-x 1 root root 4096 Apr  4 20:20 sample_data\n",
            "drwx------ 3 root root 4096 Apr 30 22:09 tools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGrfvVluSliX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tools.AR_data as ar\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P9-TxslzSliy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = ar.ARData(num_datapoints=500, num_prev=3, num_aft=1, noise_var=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Df5o2zeSli_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ec33d2f-8da1-4596-df58-aa56cb71950e"
      },
      "cell_type": "code",
      "source": [
        "data.y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "GMcVy4rvSljf",
        "colab_type": "code",
        "colab": {},
        "outputId": "f72ec22f-4e53-41f9-d354-3a5347edb053"
      },
      "cell_type": "code",
      "source": [
        "data.X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "ycPqpUr6Slju",
        "colab_type": "code",
        "colab": {},
        "outputId": "2b929926-dcd3-4449-dc79-e93face99450"
      },
      "cell_type": "code",
      "source": [
        "print(data.X_train[0:3])\n",
        "print(\"---------\")\n",
        "data.y_train[0:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.14317337  0.06001333 -2.00518375]\n",
            " [ 0.06001333 -2.00518375  0.53369902]\n",
            " [-2.00518375  0.53369902 -0.7116704 ]]\n",
            "---------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.53369902, -0.7116704 , -0.52469723],\n",
              "       [-0.7116704 , -0.52469723, -0.99014573],\n",
              "       [-0.52469723, -0.99014573, -0.78697895]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "aK2p13LhSlj6",
        "colab_type": "code",
        "colab": {},
        "outputId": "3df52b04-87f1-4be7-9200-f1ad895ecd83"
      },
      "cell_type": "code",
      "source": [
        "# data.x.shape\n",
        "data.y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "hoSbkRW_SlkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d11a422f-d964-43b3-eb2b-d42fc52c5600"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batch_size = 1\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.lstm = nn.LSTM(1,2,num_layers=2)\n",
        "        self.linear = nn.Linear(2,1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out, hid = self.lstm(x)\n",
        "        res = self.linear(out[-1:].view(1,-1))\n",
        "        \n",
        "        return res.view(1,1,1)\n",
        "    \n",
        "model = Model().cuda()\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "X = data.X_train\n",
        "y = data.y_train\n",
        "print(\"here\")\n",
        "for ep in range(n_epochs):\n",
        "    ep_loss = 0\n",
        "#     print(\"blah\")\n",
        "    for inp, tar in zip(X,y):\n",
        "#         print(str(inp)+'\\r',end='',flush=True)\n",
        "        inp = torch.autograd.Variable(\n",
        "            torch.tensor( inp, dtype=torch.float )\n",
        "        ).cuda()\n",
        "        tar = torch.autograd.Variable(\n",
        "            torch.tensor( tar, dtype=torch.float )\n",
        "        ).cuda()\n",
        "        inp = torch.reshape(inp,(3,1,1))\n",
        "        tar = torch.reshape(tar,(1,1,1))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        out = model(inp)\n",
        "#         print(out[-1:].shape)\n",
        "        loss = loss_fn(out[-1:],tar)\n",
        "        ep_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"\\r\",str(ep),str(ep_loss / len(X)),end='',flush=True)\n",
        "\n",
        "        "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "here\n",
            " 99 tensor(0.9669, device='cuda:0', grad_fn=<DivBackward0>)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_ihnWx7SlkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54898169-e468-4289-dfc3-a78f9ac8dc44"
      },
      "cell_type": "code",
      "source": [
        "val_loss = 0\n",
        "for inp,tar in zip(data.X_test, data.y_test):\n",
        "    inp = torch.autograd.Variable(\n",
        "            torch.tensor( inp, dtype=torch.float )\n",
        "        ).cuda()\n",
        "    tar = torch.autograd.Variable(\n",
        "        torch.tensor( tar, dtype=torch.float )\n",
        "    ).cuda()\n",
        "    inp = torch.reshape(inp,(3,1,1))\n",
        "    tar = torch.reshape(tar,(1,1,1))\n",
        "    out = model(inp)\n",
        "    loss = loss_fn(out[-1:],tar)\n",
        "    val_loss += loss\n",
        "print(val_loss / len(data.X_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0098, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k6a6WavWSlku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Here we define our model as a class\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,num_layers=2):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Define the LSTM layer\n",
        "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
        "\n",
        "        # Define the output layer\n",
        "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # This is what we'll initialise our hidden state as\n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Forward pass through LSTM layer\n",
        "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
        "        # shape of self.hidden: (a, b), where a and b both \n",
        "        # have shape (num_layers, batch_size, hidden_dim).\n",
        "        lstm_out, self.hidden = self.lstm(input.view((len(input), self.batch_size, -1)))\n",
        "        \n",
        "        # Only take the output from the final timetep\n",
        "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
        "        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
        "        return y_pred.view(-1)\n",
        "\n",
        "lstm_input_size = 1\n",
        "h1 = 1\n",
        "\n",
        "model = LSTM(lstm_input_size, h1, batch_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOJLu0qbSlk5",
        "colab_type": "code",
        "colab": {},
        "outputId": "942f421e-3240-42fc-d7c9-5e91f3bd7b77"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "X_train = data.X_train\n",
        "y_train = data.y_train\n",
        "# -----------------------------------------------------\n",
        "loss_fn = torch.nn.MSELoss(size_average=False)\n",
        "\n",
        "optimiser = torch.optim.Adam(model.parameters())\n",
        "\n",
        "#####################\n",
        "# Train model\n",
        "#####################\n",
        "\n",
        "hist = np.zeros(num_epochs)\n",
        "\n",
        "for t in range(num_epochs):\n",
        "    # Clear stored gradient\n",
        "    model.zero_grad()\n",
        "    \n",
        "    # Initialise hidden state\n",
        "    # Don't do this if you want your LSTM to be stateful\n",
        "    model.hidden = model.init_hidden()\n",
        "    \n",
        "    # Forward pass\n",
        "    y_pred = model(X_train)\n",
        "\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "    if t % 100 == 0:\n",
        "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
        "    hist[t] = loss.item()\n",
        "\n",
        "    # Zero out gradient, else they will accumulate between epochs\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimiser.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "data type not understood",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b1ff2aaa8f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-63a9f5db2b62>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# shape of self.hidden: (a, b), where a and b both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# have shape (num_layers, batch_size, hidden_dim).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Only take the output from the final timetep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: data type not understood"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "l-qGAOKlSllH",
        "colab_type": "code",
        "colab": {},
        "outputId": "6ba99259-2aa4-4dd8-84fe-869b14790605"
      },
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.4781265 , -0.64181071,  0.93196523],\n",
              "       [-0.64181071,  0.93196523,  1.24348954],\n",
              "       [ 0.93196523,  1.24348954, -0.45840917],\n",
              "       [ 1.24348954, -0.45840917,  0.30812605],\n",
              "       [-0.45840917,  0.30812605,  0.35834108],\n",
              "       [ 0.30812605,  0.35834108, -1.38662318],\n",
              "       [ 0.35834108, -1.38662318,  0.69901411],\n",
              "       [-1.38662318,  0.69901411,  0.24848427],\n",
              "       [ 0.69901411,  0.24848427,  0.85752616],\n",
              "       [ 0.24848427,  0.85752616, -0.11575259],\n",
              "       [ 0.85752616, -0.11575259,  0.35100975],\n",
              "       [-0.11575259,  0.35100975,  1.65124456],\n",
              "       [ 0.35100975,  1.65124456, -1.3922242 ],\n",
              "       [ 1.65124456, -1.3922242 ,  0.15814128],\n",
              "       [-1.3922242 ,  0.15814128, -0.08669572],\n",
              "       [ 0.15814128, -0.08669572, -0.18342843],\n",
              "       [-0.08669572, -0.18342843, -1.28251734],\n",
              "       [-0.18342843, -1.28251734,  0.19538482],\n",
              "       [-1.28251734,  0.19538482,  0.99293658],\n",
              "       [ 0.19538482,  0.99293658,  1.7376166 ],\n",
              "       [ 0.99293658,  1.7376166 , -0.40269675],\n",
              "       [ 1.7376166 , -0.40269675,  0.17145364],\n",
              "       [-0.40269675,  0.17145364,  1.35898702],\n",
              "       [ 0.17145364,  1.35898702,  1.50800779],\n",
              "       [ 1.35898702,  1.50800779,  1.38457897],\n",
              "       [ 1.50800779,  1.38457897,  0.5145979 ],\n",
              "       [ 1.38457897,  0.5145979 ,  0.60961806],\n",
              "       [ 0.5145979 ,  0.60961806, -0.21025008],\n",
              "       [ 0.60961806, -0.21025008, -0.68817408],\n",
              "       [-0.21025008, -0.68817408, -0.54135607],\n",
              "       [-0.68817408, -0.54135607, -0.75009847],\n",
              "       [-0.54135607, -0.75009847,  0.2374333 ],\n",
              "       [-0.75009847,  0.2374333 ,  0.24394397],\n",
              "       [ 0.2374333 ,  0.24394397, -0.03320528],\n",
              "       [ 0.24394397, -0.03320528,  0.46335582],\n",
              "       [-0.03320528,  0.46335582, -0.22295802],\n",
              "       [ 0.46335582, -0.22295802, -1.08356983],\n",
              "       [-0.22295802, -1.08356983, -0.17776479],\n",
              "       [-1.08356983, -0.17776479, -0.03359413],\n",
              "       [-0.17776479, -0.03359413,  0.04046582]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "WFNx-oyVSllX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###########################################################################"
      ]
    },
    {
      "metadata": {
        "id": "_I2DLGneSllZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hid_base = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
        "inp_base = [torch.randn(1, 3) for _ in range(4)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BmjR2MggSllf",
        "colab_type": "code",
        "colab": {},
        "outputId": "33e99eec-c489-4c26-8e82-797d8cb82a22"
      },
      "cell_type": "code",
      "source": [
        "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
        "# inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
        "inputs = inp_base\n",
        "\n",
        "# initialize the hidden state.\n",
        "# hidden = (torch.randn(1, 1, 3),\n",
        "#           torch.randn(1, 1, 3))\n",
        "hidden = hid_base\n",
        "\n",
        "# for i in range(8):\n",
        "#     # Step through the sequence one element at a time.\n",
        "#     # after each step, hidden contains the hidden state.\n",
        "#     out, hidden = lstm(inputs[i].view(1, 1, -1), hidden)\n",
        "#     inputs.append(out)\n",
        "#     print(out)\n",
        "#     print(hidden)\n",
        "#     print(\"-------------------\")\n",
        "\n",
        "# print(\"==============\")\n",
        "\n",
        "# alternatively, we can do the entire sequence all at once.\n",
        "# the first value returned by LSTM is all of the hidden states throughout\n",
        "# the sequence. the second is just the most recent hidden state\n",
        "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
        "# The reason for this is that:\n",
        "# \"out\" will give you access to all hidden states in the sequence\n",
        "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
        "# by passing it as an argument  to the lstm at a later time\n",
        "# Add the extra 2nd dimension\n",
        "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "# hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
        "hidden = hid_base\n",
        "out, hidden = lstm(inputs, hidden)\n",
        "print(out)\n",
        "print(hidden)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.1053,  0.4817, -0.1503]],\n",
            "\n",
            "        [[-0.2229,  0.5812, -0.3411]],\n",
            "\n",
            "        [[ 0.4357,  0.1472, -0.5547]],\n",
            "\n",
            "        [[ 0.3102, -0.0966, -0.4476]]], grad_fn=<StackBackward>)\n",
            "(tensor([[[ 0.3102, -0.0966, -0.4476]]], grad_fn=<StackBackward>), tensor([[[ 0.5090, -0.2803, -0.6513]]], grad_fn=<StackBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ce0PWWZeSllp",
        "colab_type": "code",
        "colab": {},
        "outputId": "31b312b5-32f2-4ffe-94a4-9148df3432cd"
      },
      "cell_type": "code",
      "source": [
        "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.6518, 0.7962, 0.3739]]),\n",
              " tensor([[-0.3925, -0.4316,  0.3713]]),\n",
              " tensor([[ 0.7826,  0.2304, -0.2615]]),\n",
              " tensor([[-0.3522, -0.6057,  0.8928]]),\n",
              " tensor([[-0.0165,  1.3197, -0.0099]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "Wi1uSWubSll3",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f80949c-b272-4223-e252-1e6f1606d725"
      },
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "snKf4sDFSlmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}