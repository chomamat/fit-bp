{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/chomamat/fit-bp/blob/master/13_niklaus_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "yJLL7hF9b_b6",
    "outputId": "3dbd3409-7056-4833-c9d2-4651ac37f813"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!cp gdrive/My\\ Drive/x64/*.npy .\n",
    "!cp gdrive/My\\ Drive/*.py .\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "Cv0etV0vcKT4",
    "outputId": "ca993fb5-c144-4359-9a45-4336d5e6c2ab"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import _torch_tools as tt\n",
    "import _my_tools as mt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)\n",
    "X_train, y_train, X_test, y_test = mt.loadData(\"dataset_interpolation/\",'float16',channels_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_SIZE = 31\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "# taken from Kartasev et al.\n",
    "class SeparableConvolutionSlow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SeparableConvolutionSlow, self).__init__()\n",
    "    \n",
    "    def forward(self, im, vertical, horizontal):\n",
    "        n_b = im.size(0)\n",
    "        n_channels = im.size(1)\n",
    "        m = im.size(2)\n",
    "        m_out = m - FILTER_SIZE + 1\n",
    "        \n",
    "        assert im.size(2) == im.size(3)\n",
    "        assert vertical.size(0) == horizontal.size(0) == n_b\n",
    "        assert vertical.size(1) == horizontal.size(1) == FILTER_SIZE\n",
    "        assert vertical.size(2) == horizontal.size(2) == vertical.size(3) == horizontal.size(3) == m_out\n",
    "\n",
    "        n_workers = NUM_WORKERS\n",
    "\n",
    "        if os.name == 'nt' and NUM_WORKERS > 1:\n",
    "#             print('Parallel Separable Convolution on CPU not supported on Windows. Proceeding on main thread...')\n",
    "            n_workers = 1\n",
    "\n",
    "        if vertical.requires_grad and NUM_WORKERS > 1:\n",
    "#             print('Parallel Separable Convolution on CPU not supported during training. Proceeding on main thread...')\n",
    "            n_workers = 1\n",
    "\n",
    "        output = im.new().resize_(n_b, n_channels, m_out, m_out).zero_()\n",
    "\n",
    "        if n_workers > 1:\n",
    "            return parallel_sep_conv(im, horizontal, vertical, output, n_workers)\n",
    "        else:\n",
    "            return sep_conv(im, horizontal, vertical, output)\n",
    "\n",
    "\n",
    "def local_separable_conv_2d(im, horizontal, vertical, output=None):\n",
    "    \"\"\"im: [n_channels x m x m], horizontal: [51 x m x m], vertical: [51 x m x m]\n",
    "       -> return: [n_channels x (m - 50) x (m - 50)]\"\"\"\n",
    "    n_channels = im.size(0)\n",
    "    m = im.size(1)\n",
    "    m_out = m - FILTER_SIZE + 1\n",
    "    if output is None:\n",
    "        output = t.zeros((n_channels, m_out, m_out))\n",
    "    for row in range(m_out):\n",
    "        for col in range(m_out):\n",
    "            sub_patch = im[:, row:row + FILTER_SIZE, col:col + FILTER_SIZE]\n",
    "            local_horiz = horizontal[:, row, col]\n",
    "            local_vert = vertical[:, row, col].view(-1, 1)\n",
    "            output[:, row, col] = (sub_patch * local_horiz * local_vert).sum(dim=1).sum(dim=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def _sep_conv_worker(im, horizontal, vertical, output, worker_batch_size, offset):\n",
    "    n_b = im.size(0)\n",
    "    max_range = min(n_b, worker_batch_size+offset)\n",
    "    for b in range(offset, max_range):\n",
    "        local_separable_conv_2d(im[b], horizontal[b], vertical[b], output=output[b])\n",
    "    return output\n",
    "\n",
    "\n",
    "def sep_conv(im, horizontal, vertical, output):\n",
    "    \"\"\"\n",
    "    Runs the separable convolution on multiple images sequentially on a single thread\n",
    "    :param im: Input images as a tensor. im[0] must correspond to the first image of the batch\n",
    "    :param horizontal: Set of horizontal filters as a tensor\n",
    "    :param vertical: Set of vertical filters as a tensor\n",
    "    :param output: Tensor used as output. Same shape as im. Must be passed pre-allocated and initialized with zeros\n",
    "    :return: Tensor resulting from the convolution\n",
    "    \"\"\"\n",
    "    return _sep_conv_worker(im, horizontal, vertical, output, im.size(0), 0)\n",
    "\n",
    "\n",
    "def parallel_sep_conv(im, horizontal, vertical, output, n_workers):\n",
    "    \"\"\"\n",
    "    Spawns the specified amount of workers to run the separable convolution on multiple images in parallel\n",
    "    :param im: Input images as a tensor. im[0] must correspond to the first image of the batch\n",
    "    :param horizontal: Set of horizontal filters as a tensor\n",
    "    :param vertical: Set of vertical filters as a tensor\n",
    "    :param output: Tensor used as output. Same shape as im. Must be passed pre-allocated and initialized with zeros\n",
    "    :param n_workers: Number of workers to be used. Must be greater than zero\n",
    "    :return: Tensor resulting from the convolution\n",
    "    \"\"\"\n",
    "\n",
    "    n_b = im.size(0)\n",
    "    n_workers = min(n_b, n_workers)\n",
    "    worker_batch_size = n_b // n_workers\n",
    "    processes = []\n",
    "\n",
    "    output.share_memory_()\n",
    "\n",
    "    for i in range(n_workers):\n",
    "\n",
    "        offset = worker_batch_size * i\n",
    "        if i == n_workers-1:\n",
    "            worker_batch_size += n_b % n_workers\n",
    "\n",
    "        p = mp.Process(target=_sep_conv_worker, args=(im, horizontal, vertical, output, worker_batch_size, offset,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGB9ssv8cqX0"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.KERNEL_SIZE = 31\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "        self.conv_setup = {\n",
    "            'kernel' : (3,3),\n",
    "            'stride' : (1,1),\n",
    "            'padding' : 1,\n",
    "            'activation' : self.activation\n",
    "        }\n",
    "        self.pooling_setup = {\n",
    "            'kernel_size' : (2,2),\n",
    "            'stride' : (2,2)\n",
    "        }\n",
    "        self.upsample_setup = {\n",
    "            'scale_factor' : 2,\n",
    "            'mode' : 'bilinear',\n",
    "            'align_corners' : True\n",
    "        }\n",
    "\n",
    "        self.pooling_layer = nn.AvgPool2d(**self.pooling_setup)\n",
    "        self.upsample_layer = nn.Upsample(**self.upsample_setup)\n",
    "        self.pad = nn.ReplicationPad2d(self.KERNEL_SIZE // 2)\n",
    "        \n",
    "        self.conv32 = self._convBlock(2, 32, **self.conv_setup)\n",
    "        self.conv64 = self._convBlock(32, 64, **self.conv_setup)\n",
    "        self.conv128 = self._convBlock(64, 128, **self.conv_setup)\n",
    "        self.conv256 = self._convBlock(128, 256, **self.conv_setup)\n",
    "        \n",
    "        self.conv256_256 = self._convBlock(256, 256, **self.conv_setup)\n",
    "\n",
    "        self.upsample256 = self._upsampleBlock(self.upsample_layer, 256, 256, **self.conv_setup)\n",
    "        self.deconv128 = self._convBlock(256, 128, **self.conv_setup)\n",
    "        self.upsample128 = self._upsampleBlock(self.upsample_layer, 128, 128, **self.conv_setup)\n",
    "        self.deconv64 = self._convBlock(128, 64, **self.conv_setup)\n",
    "        self.upsample64 = self._upsampleBlock(self.upsample_layer, 64, 64, **self.conv_setup)\n",
    "        \n",
    "        self.kernel_1h = self._kernelBlock(self.upsample_layer, 64, self.KERNEL_SIZE, **self.conv_setup)\n",
    "        self.kernel_1v = self._kernelBlock(self.upsample_layer, 64, self.KERNEL_SIZE, **self.conv_setup)\n",
    "        self.kernel_2h = self._kernelBlock(self.upsample_layer, 64, self.KERNEL_SIZE, **self.conv_setup)\n",
    "        self.kernel_2v = self._kernelBlock(self.upsample_layer, 64, self.KERNEL_SIZE, **self.conv_setup)\n",
    "        \n",
    "        self.separable_conv = SeparableConvolutionSlow()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        img1 = x[:,:1,:,:]\n",
    "        img2 = x[:,1:,:,:]\n",
    "        \n",
    "        # compression\n",
    "        \n",
    "        x32 = self.conv32(x)\n",
    "        x32_p = self.pooling_layer(x32)\n",
    "        x64 = self.conv64(x32_p)\n",
    "        x64_p = self.pooling_layer(x64)\n",
    "        x128 = self.conv128(x64_p)\n",
    "        x128_p = self.pooling_layer(x128)\n",
    "        x256 = self.conv256(x128_p)\n",
    "        x256_p = self.pooling_layer(x256)\n",
    "\n",
    "        x = self.conv256_256(x256_p)\n",
    "\n",
    "        # expansion\n",
    "\n",
    "        x = self.upsample256(x)\n",
    "        x += x256\n",
    "        x = self.deconv128(x)\n",
    "\n",
    "        x = self.upsample128(x)\n",
    "        x += x128\n",
    "        x = self.deconv64(x)\n",
    "\n",
    "        x = self.upsample64(x)\n",
    "        x += x64\n",
    "        \n",
    "        # creating kernels & image padding\n",
    "        \n",
    "        k_1h = self.kernel_1h(x)\n",
    "        k_1v = self.kernel_1v(x)\n",
    "        k_2h = self.kernel_2h(x)\n",
    "        k_2v = self.kernel_2v(x)\n",
    "        \n",
    "        p_img1 = self.pad(img1)\n",
    "        p_img2 = self.pad(img2)\n",
    "                \n",
    "        return self.separable_conv(p_img1, k_1v, k_1h) + self.separable_conv(p_img2, k_2v, k_2h)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _convBlock(in_channels, out_channels, kernel, stride, padding, activation):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), activation,\n",
    "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), activation,\n",
    "            nn.Conv2d(in_channels, out_channels, kernel, stride, padding), activation\n",
    "        )\n",
    "    @staticmethod\n",
    "    def _kernelBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), activation,\n",
    "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), activation,\n",
    "            nn.Conv2d(in_channels, out_channels, kernel, stride, padding), activation,\n",
    "            upsample,\n",
    "            nn.Conv2d(out_channels, out_channels, kernel, stride, padding)\n",
    "        )\n",
    "    @staticmethod\n",
    "    def _upsampleBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation):\n",
    "        return nn.Sequential(\n",
    "            upsample,\n",
    "            nn.Conv2d(in_channels, out_channels, kernel, stride, padding), activation\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "training = tt.Training(model, device, X_train, y_train, X_test, y_test)\n",
    "training.fit(16, 2, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model( torch.tensor(X_test[0:10], dtype=torch.float).to(device) )\n",
    "for i in range(10):\n",
    "    mt.compare(i, X_test, y_test, out.cpu().detach().numpy(), channels_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"weights\")\n",
    "!zip fig.zip *.png"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "13_niklaus_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
