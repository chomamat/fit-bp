{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools._dataset_tools as dt\n",
    "import tools._my_tools as mt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Cropping\n",
    "All of the grayscale radar images from folder `datasets/dataset_full/` are taken and squares of size $96\\times96$ are cropped from them with a stride of size $48$. The cropped squares are saved in `datasets/cropped_96_96/` in folder according to the square's coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_f = \"datasets/cropped_96_96/\"\n",
    "in_f = \"datasets/dataset_full/\"\n",
    "\n",
    "for f in range(55):\n",
    "    os.mkdir(out_f+str(f).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.cropFolder(in_f,out_f,96,48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Triplets Finding\n",
    "All images from every folder of `datasets/cropped_96_96/` are taken, and images that have more than $95\\%$ of the area without precipitation or have only precipitation of level $1$ (of $16$) are deleted. The previous images may also be removed so that there are in the end always left three consecutive images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = \"datasets/cropped_96_96/\"\n",
    "for folder in sorted(os.listdir(in_f)):\n",
    "    dt.findSequence(in_f+folder+\"/\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading to NumPy Array\n",
    "\n",
    "Load all files in every folder to X, y numpy arrays by folders. Rotations are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder datasets/cropped_96_96/ 00\n",
      "In folder: 2947 \t\tTotal: 2947\n",
      "Processing folder datasets/cropped_96_96/ 01\n",
      "In folder: 3383 \t\tTotal: 6330\n",
      "Processing folder datasets/cropped_96_96/ 02\n",
      "In folder: 3516 \t\tTotal: 9846\n",
      "Processing folder datasets/cropped_96_96/ 03\n",
      "In folder: 3413 \t\tTotal: 13259\n",
      "Processing folder datasets/cropped_96_96/ 04\n",
      "In folder: 3405 \t\tTotal: 16664\n",
      "Processing folder datasets/cropped_96_96/ 05\n",
      "In folder: 3375 \t\tTotal: 20039\n",
      "Processing folder datasets/cropped_96_96/ 06\n",
      "In folder: 3422 \t\tTotal: 23461\n",
      "Processing folder datasets/cropped_96_96/ 07\n",
      "In folder: 3459 \t\tTotal: 26920\n",
      "Processing folder datasets/cropped_96_96/ 08\n",
      "In folder: 3239 \t\tTotal: 30159\n",
      "Processing folder datasets/cropped_96_96/ 09\n",
      "In folder: 2918 \t\tTotal: 33077\n",
      "Processing folder datasets/cropped_96_96/ 10\n",
      "In folder: 2734 \t\tTotal: 35811\n",
      "Processing folder datasets/cropped_96_96/ 11\n",
      "In folder: 3433 \t\tTotal: 39244\n",
      "Processing folder datasets/cropped_96_96/ 12\n",
      "In folder: 3788 \t\tTotal: 43032\n",
      "Processing folder datasets/cropped_96_96/ 13\n",
      "In folder: 3901 \t\tTotal: 46933\n",
      "Processing folder datasets/cropped_96_96/ 14\n",
      "In folder: 3763 \t\tTotal: 50696\n",
      "Processing folder datasets/cropped_96_96/ 15\n",
      "In folder: 3760 \t\tTotal: 54456\n",
      "Processing folder datasets/cropped_96_96/ 16\n",
      "In folder: 3639 \t\tTotal: 58095\n",
      "Processing folder datasets/cropped_96_96/ 17\n",
      "In folder: 3908 \t\tTotal: 62003\n",
      "Processing folder datasets/cropped_96_96/ 18\n",
      "In folder: 4202 \t\tTotal: 66205\n",
      "Processing folder datasets/cropped_96_96/ 19\n",
      "In folder: 4087 \t\tTotal: 70292\n",
      "Processing folder datasets/cropped_96_96/ 20\n",
      "In folder: 3710 \t\tTotal: 74002\n",
      "Processing folder datasets/cropped_96_96/ 21\n",
      "In folder: 3449 \t\tTotal: 77451\n",
      "Processing folder datasets/cropped_96_96/ 22\n",
      "In folder: 3594 \t\tTotal: 81045\n",
      "Processing folder datasets/cropped_96_96/ 23\n",
      "In folder: 3894 \t\tTotal: 84939\n",
      "Processing folder datasets/cropped_96_96/ 24\n",
      "In folder: 4198 \t\tTotal: 89137\n",
      "Processing folder datasets/cropped_96_96/ 25\n",
      "In folder: 4240 \t\tTotal: 93377\n",
      "Processing folder datasets/cropped_96_96/ 26\n",
      "In folder: 4035 \t\tTotal: 97412\n",
      "Processing folder datasets/cropped_96_96/ 27\n",
      "In folder: 3989 \t\tTotal: 101401\n",
      "Processing folder datasets/cropped_96_96/ 28\n",
      "In folder: 4505 \t\tTotal: 105906\n",
      "Processing folder datasets/cropped_96_96/ 29\n",
      "In folder: 5060 \t\tTotal: 110966\n",
      "Processing folder datasets/cropped_96_96/ 30\n",
      "In folder: 4898 \t\tTotal: 115864\n",
      "Processing folder datasets/cropped_96_96/ 31\n",
      "In folder: 4439 \t\tTotal: 120303\n",
      "Processing folder datasets/cropped_96_96/ 32\n",
      "In folder: 3988 \t\tTotal: 124291\n",
      "Processing folder datasets/cropped_96_96/ 33\n",
      "In folder: 3709 \t\tTotal: 128000\n",
      "Processing folder datasets/cropped_96_96/ 34\n",
      "In folder: 4142 \t\tTotal: 132142\n",
      "Processing folder datasets/cropped_96_96/ 35\n",
      "In folder: 4643 \t\tTotal: 136785\n",
      "Processing folder datasets/cropped_96_96/ 36\n",
      "In folder: 4729 \t\tTotal: 141514\n",
      "Processing folder datasets/cropped_96_96/ 37\n",
      "In folder: 4395 \t\tTotal: 145909\n",
      "Processing folder datasets/cropped_96_96/ 38\n",
      "In folder: 4325 \t\tTotal: 150234\n",
      "Processing folder datasets/cropped_96_96/ 39\n",
      "In folder: 4702 \t\tTotal: 154936\n",
      "Processing folder datasets/cropped_96_96/ 40\n",
      "In folder: 5055 \t\tTotal: 159991\n",
      "Processing folder datasets/cropped_96_96/ 41\n",
      "In folder: 4965 \t\tTotal: 164956\n",
      "Processing folder datasets/cropped_96_96/ 42\n",
      "In folder: 4606 \t\tTotal: 169562\n",
      "Processing folder datasets/cropped_96_96/ 43\n",
      "In folder: 4196 \t\tTotal: 173758\n",
      "Processing folder datasets/cropped_96_96/ 44\n",
      "In folder: 3699 \t\tTotal: 177457\n",
      "Processing folder datasets/cropped_96_96/ 45\n",
      "In folder: 4155 \t\tTotal: 181612\n",
      "Processing folder datasets/cropped_96_96/ 46\n",
      "In folder: 4660 \t\tTotal: 186272\n",
      "Processing folder datasets/cropped_96_96/ 47\n",
      "In folder: 4694 \t\tTotal: 190966\n",
      "Processing folder datasets/cropped_96_96/ 48\n",
      "In folder: 4540 \t\tTotal: 195506\n",
      "Processing folder datasets/cropped_96_96/ 49\n",
      "In folder: 4437 \t\tTotal: 199943\n",
      "Processing folder datasets/cropped_96_96/ 50\n",
      "In folder: 4528 \t\tTotal: 204471\n",
      "Processing folder datasets/cropped_96_96/ 51\n",
      "In folder: 4674 \t\tTotal: 209145\n",
      "Processing folder datasets/cropped_96_96/ 52\n",
      "In folder: 4531 \t\tTotal: 213676\n",
      "Processing folder datasets/cropped_96_96/ 53\n",
      "In folder: 4313 \t\tTotal: 217989\n",
      "Processing folder datasets/cropped_96_96/ 54\n",
      "In folder: 4045 \t\tTotal: 222034\n"
     ]
    }
   ],
   "source": [
    "in_f = \"datasets/cropped_96_96/\"\n",
    "folders = sorted(os.listdir(in_f))\n",
    "X_sum = 0\n",
    "# -------------------------------------------------------\n",
    "for i in range(0,55):\n",
    "    print(\"Processing folder\", in_f, folders[i])\n",
    "    \n",
    "    X_tmp,y_tmp = dt.loadToNPA(in_f+folders[i]+\"/\")\n",
    "    X_tmp = np.rot90(X_tmp,k=i%4,axes=(2,3))          # rotate the image\n",
    "    y_tmp = np.rot90(y_tmp,k=i%4,axes=(1,2))          # rotate the image. Axis (1,2) because there is no channel information in y_tmp yet.\n",
    "    \n",
    "    np.save(\"datasets/cropped_96_96/loaded/\"+str(i)+\"_X\",X_tmp)\n",
    "    np.save(\"datasets/cropped_96_96/loaded/\"+str(i)+\"_y\",y_tmp)\n",
    "    \n",
    "    X_sum += X_tmp.shape[0]\n",
    "    \n",
    "    print(\"In folder:\",X_tmp.shape[0],\"\\t\\tTotal:\",Xsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of X: (222034, 2, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "in_f = \"datasets/cropped_96_96/loaded/\"\n",
    "X = np.load(in_f+\"0_X.npy\")\n",
    "# -------------------------------------------------------\n",
    "for i in range(1,55):\n",
    "    X_tmp = np.load(in_f+str(i)+\"_X.npy\")\n",
    "    X = np.concatenate((X,X_tmp),axis=0)\n",
    "# -------------------------------------------------------\n",
    "print(\"Final shape of X:\",X.shape)\n",
    "np.save(\"datasets/dataset_interpolation_96/full/X\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of y: (222034, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "in_f = \"datasets/cropped_96_96/loaded/\"\n",
    "y = np.load(in_f+\"0_y.npy\")\n",
    "# -------------------------------------------------------\n",
    "for i in range(1,55):\n",
    "    y_tmp = np.load(in_f+str(i)+\"_y.npy\")\n",
    "    y = np.concatenate((y,y_tmp),axis=0)\n",
    "y = np.expand_dims(y,1)                     # expand the dimensions so it fits with x\n",
    "# -------------------------------------------------------\n",
    "print(\"Final shape of y:\",y.shape)\n",
    "np.save(\"datasets/dataset_interpolation_96/full/y\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset\n",
    "The test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 1\n",
      "check 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# -------------------------------------------------------\n",
    "in_f = \"datasets/dataset_interpolation_96/full/\"\n",
    "out_f = \"datasets/dataset_interpolation_96/\"\n",
    "\n",
    "X = np.load(in_f+\"X.npy\")\n",
    "y = np.load(in_f+\"y.npy\")\n",
    "print(\"check 1\")\n",
    "# -------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "print(\"check 2\")\n",
    "# -------------------------------------------------------\n",
    "np.save(out_f+\"X_train_tmp\",X_train)\n",
    "np.save(out_f+\"y_train_tmp\",y_train)\n",
    "np.save(out_f+\"X_test\",X_test)\n",
    "np.save(out_f+\"y_test\",y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 1\n",
      "check 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# -------------------------------------------------------\n",
    "in_f = \"datasets/dataset_interpolation_96/\"\n",
    "out_f = \"datasets/dataset_interpolation_96/\"\n",
    "\n",
    "X = np.load(in_f+\"X_train_tmp.npy\")\n",
    "y = np.load(in_f+\"y_train_tmp.npy\")\n",
    "print(\"check 1\")\n",
    "# -------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "print(\"check 2\")\n",
    "# -------------------------------------------------------\n",
    "np.save(out_f+\"X_train\",X_train)\n",
    "np.save(out_f+\"y_train\",y_train)\n",
    "np.save(out_f+\"X_val\",X_val)\n",
    "np.save(out_f+\"y_val\",y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================\n",
    "\n",
    "================================================================\n",
    "\n",
    "================================================================\n",
    "## Part 2: 3 images -> 3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = \"datasets/cropped_seq_6/\"\n",
    "source_f = \"datasets/dataset_full/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(55):\n",
    "    os.mkdir(in_f+str(f).zfill(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop $96\\times 96$ patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radarcs1810312350.png\r"
     ]
    }
   ],
   "source": [
    "dt.cropFolder(source_f,in_f,96,48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove images with no information and group them to sequences of $6$ consecutive images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In folder \"datasets/cropped_seq_6/00/\" where left 8280 images.\n",
      "In folder \"datasets/cropped_seq_6/01/\" where left 9642 images.\n",
      "In folder \"datasets/cropped_seq_6/02/\" where left 9906 images.\n",
      "In folder \"datasets/cropped_seq_6/03/\" where left 9642 images.\n",
      "In folder \"datasets/cropped_seq_6/04/\" where left 9582 images.\n",
      "In folder \"datasets/cropped_seq_6/05/\" where left 9600 images.\n",
      "In folder \"datasets/cropped_seq_6/06/\" where left 9684 images.\n",
      "In folder \"datasets/cropped_seq_6/07/\" where left 9822 images.\n",
      "In folder \"datasets/cropped_seq_6/08/\" where left 9150 images.\n",
      "In folder \"datasets/cropped_seq_6/09/\" where left 8202 images.\n",
      "In folder \"datasets/cropped_seq_6/10/\" where left 7692 images.\n",
      "In folder \"datasets/cropped_seq_6/11/\" where left 9816 images.\n",
      "In folder \"datasets/cropped_seq_6/12/\" where left 10800 images.\n",
      "In folder \"datasets/cropped_seq_6/13/\" where left 11154 images.\n",
      "In folder \"datasets/cropped_seq_6/14/\" where left 10728 images.\n",
      "In folder \"datasets/cropped_seq_6/15/\" where left 10698 images.\n",
      "In folder \"datasets/cropped_seq_6/16/\" where left 10332 images.\n",
      "In folder \"datasets/cropped_seq_6/17/\" where left 11130 images.\n",
      "In folder \"datasets/cropped_seq_6/18/\" where left 11970 images.\n",
      "In folder \"datasets/cropped_seq_6/19/\" where left 11640 images.\n",
      "In folder \"datasets/cropped_seq_6/20/\" where left 10542 images.\n",
      "In folder \"datasets/cropped_seq_6/21/\" where left 9828 images.\n",
      "In folder \"datasets/cropped_seq_6/22/\" where left 10296 images.\n",
      "In folder \"datasets/cropped_seq_6/23/\" where left 11136 images.\n",
      "In folder \"datasets/cropped_seq_6/24/\" where left 12102 images.\n",
      "In folder \"datasets/cropped_seq_6/25/\" where left 12168 images.\n",
      "In folder \"datasets/cropped_seq_6/26/\" where left 11556 images.\n",
      "In folder \"datasets/cropped_seq_6/27/\" where left 11430 images.\n",
      "In folder \"datasets/cropped_seq_6/28/\" where left 12798 images.\n",
      "In folder \"datasets/cropped_seq_6/29/\" where left 14442 images.\n",
      "In folder \"datasets/cropped_seq_6/30/\" where left 14004 images.\n",
      "In folder \"datasets/cropped_seq_6/31/\" where left 12744 images.\n",
      "In folder \"datasets/cropped_seq_6/32/\" where left 11310 images.\n",
      "In folder \"datasets/cropped_seq_6/33/\" where left 10602 images.\n",
      "In folder \"datasets/cropped_seq_6/34/\" where left 11928 images.\n",
      "In folder \"datasets/cropped_seq_6/35/\" where left 13296 images.\n",
      "In folder \"datasets/cropped_seq_6/36/\" where left 13608 images.\n",
      "In folder \"datasets/cropped_seq_6/37/\" where left 12606 images.\n",
      "In folder \"datasets/cropped_seq_6/38/\" where left 12336 images.\n",
      "In folder \"datasets/cropped_seq_6/39/\" where left 13476 images.\n",
      "In folder \"datasets/cropped_seq_6/40/\" where left 14472 images.\n",
      "In folder \"datasets/cropped_seq_6/41/\" where left 14172 images.\n",
      "In folder \"datasets/cropped_seq_6/42/\" where left 13200 images.\n",
      "In folder \"datasets/cropped_seq_6/43/\" where left 11988 images.\n",
      "In folder \"datasets/cropped_seq_6/44/\" where left 10614 images.\n",
      "In folder \"datasets/cropped_seq_6/45/\" where left 11916 images.\n",
      "In folder \"datasets/cropped_seq_6/46/\" where left 13458 images.\n",
      "In folder \"datasets/cropped_seq_6/47/\" where left 13554 images.\n",
      "In folder \"datasets/cropped_seq_6/48/\" where left 13050 images.\n",
      "In folder \"datasets/cropped_seq_6/49/\" where left 12666 images.\n",
      "In folder \"datasets/cropped_seq_6/50/\" where left 12936 images.\n",
      "In folder \"datasets/cropped_seq_6/51/\" where left 13392 images.\n",
      "In folder \"datasets/cropped_seq_6/52/\" where left 12870 images.\n",
      "In folder \"datasets/cropped_seq_6/53/\" where left 12318 images.\n",
      "In folder \"datasets/cropped_seq_6/54/\" where left 11598 images.\n"
     ]
    }
   ],
   "source": [
    "for folder in sorted(os.listdir(in_f)):\n",
    "    dt.findSequence(in_f+folder+\"/\", 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images from each folder in $\\{00,01,\\dots,54\\}$ to a separate numpy arrays X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder datasets/cropped_seq_6/ 00\n",
      "In folder: 1380 \t\tTotal: 1380\n",
      "Processing folder datasets/cropped_seq_6/ 01\n",
      "In folder: 1607 \t\tTotal: 2987\n",
      "Processing folder datasets/cropped_seq_6/ 02\n",
      "In folder: 1651 \t\tTotal: 4638\n",
      "Processing folder datasets/cropped_seq_6/ 03\n",
      "In folder: 1607 \t\tTotal: 6245\n",
      "Processing folder datasets/cropped_seq_6/ 04\n",
      "In folder: 1597 \t\tTotal: 7842\n",
      "Processing folder datasets/cropped_seq_6/ 05\n",
      "In folder: 1600 \t\tTotal: 9442\n",
      "Processing folder datasets/cropped_seq_6/ 06\n",
      "In folder: 1614 \t\tTotal: 11056\n",
      "Processing folder datasets/cropped_seq_6/ 07\n",
      "In folder: 1637 \t\tTotal: 12693\n",
      "Processing folder datasets/cropped_seq_6/ 08\n",
      "In folder: 1525 \t\tTotal: 14218\n",
      "Processing folder datasets/cropped_seq_6/ 09\n",
      "In folder: 1367 \t\tTotal: 15585\n",
      "Processing folder datasets/cropped_seq_6/ 10\n",
      "In folder: 1282 \t\tTotal: 16867\n",
      "Processing folder datasets/cropped_seq_6/ 11\n",
      "In folder: 1636 \t\tTotal: 18503\n",
      "Processing folder datasets/cropped_seq_6/ 12\n",
      "In folder: 1800 \t\tTotal: 20303\n",
      "Processing folder datasets/cropped_seq_6/ 13\n",
      "In folder: 1859 \t\tTotal: 22162\n",
      "Processing folder datasets/cropped_seq_6/ 14\n",
      "In folder: 1788 \t\tTotal: 23950\n",
      "Processing folder datasets/cropped_seq_6/ 15\n",
      "In folder: 1783 \t\tTotal: 25733\n",
      "Processing folder datasets/cropped_seq_6/ 16\n",
      "In folder: 1722 \t\tTotal: 27455\n",
      "Processing folder datasets/cropped_seq_6/ 17\n",
      "In folder: 1855 \t\tTotal: 29310\n",
      "Processing folder datasets/cropped_seq_6/ 18\n",
      "In folder: 1995 \t\tTotal: 31305\n",
      "Processing folder datasets/cropped_seq_6/ 19\n",
      "In folder: 1940 \t\tTotal: 33245\n",
      "Processing folder datasets/cropped_seq_6/ 20\n",
      "In folder: 1757 \t\tTotal: 35002\n",
      "Processing folder datasets/cropped_seq_6/ 21\n",
      "In folder: 1638 \t\tTotal: 36640\n",
      "Processing folder datasets/cropped_seq_6/ 22\n",
      "In folder: 1716 \t\tTotal: 38356\n",
      "Processing folder datasets/cropped_seq_6/ 23\n",
      "In folder: 1856 \t\tTotal: 40212\n",
      "Processing folder datasets/cropped_seq_6/ 24\n",
      "In folder: 2017 \t\tTotal: 42229\n",
      "Processing folder datasets/cropped_seq_6/ 25\n",
      "In folder: 2028 \t\tTotal: 44257\n",
      "Processing folder datasets/cropped_seq_6/ 26\n",
      "In folder: 1926 \t\tTotal: 46183\n",
      "Processing folder datasets/cropped_seq_6/ 27\n",
      "In folder: 1905 \t\tTotal: 48088\n",
      "Processing folder datasets/cropped_seq_6/ 28\n",
      "In folder: 2133 \t\tTotal: 50221\n",
      "Processing folder datasets/cropped_seq_6/ 29\n",
      "In folder: 2407 \t\tTotal: 52628\n",
      "Processing folder datasets/cropped_seq_6/ 30\n",
      "In folder: 2334 \t\tTotal: 54962\n",
      "Processing folder datasets/cropped_seq_6/ 31\n",
      "In folder: 2124 \t\tTotal: 57086\n",
      "Processing folder datasets/cropped_seq_6/ 32\n",
      "In folder: 1885 \t\tTotal: 58971\n",
      "Processing folder datasets/cropped_seq_6/ 33\n",
      "In folder: 1767 \t\tTotal: 60738\n",
      "Processing folder datasets/cropped_seq_6/ 34\n",
      "In folder: 1988 \t\tTotal: 62726\n",
      "Processing folder datasets/cropped_seq_6/ 35\n",
      "In folder: 2216 \t\tTotal: 64942\n",
      "Processing folder datasets/cropped_seq_6/ 36\n",
      "In folder: 2268 \t\tTotal: 67210\n",
      "Processing folder datasets/cropped_seq_6/ 37\n",
      "In folder: 2101 \t\tTotal: 69311\n",
      "Processing folder datasets/cropped_seq_6/ 38\n",
      "In folder: 2056 \t\tTotal: 71367\n",
      "Processing folder datasets/cropped_seq_6/ 39\n",
      "In folder: 2246 \t\tTotal: 73613\n",
      "Processing folder datasets/cropped_seq_6/ 40\n",
      "In folder: 2412 \t\tTotal: 76025\n",
      "Processing folder datasets/cropped_seq_6/ 41\n",
      "In folder: 2362 \t\tTotal: 78387\n",
      "Processing folder datasets/cropped_seq_6/ 42\n",
      "In folder: 2200 \t\tTotal: 80587\n",
      "Processing folder datasets/cropped_seq_6/ 43\n",
      "In folder: 1998 \t\tTotal: 82585\n",
      "Processing folder datasets/cropped_seq_6/ 44\n",
      "In folder: 1769 \t\tTotal: 84354\n",
      "Processing folder datasets/cropped_seq_6/ 45\n",
      "In folder: 1986 \t\tTotal: 86340\n",
      "Processing folder datasets/cropped_seq_6/ 46\n",
      "In folder: 2243 \t\tTotal: 88583\n",
      "Processing folder datasets/cropped_seq_6/ 47\n",
      "In folder: 2259 \t\tTotal: 90842\n",
      "Processing folder datasets/cropped_seq_6/ 48\n",
      "In folder: 2175 \t\tTotal: 93017\n",
      "Processing folder datasets/cropped_seq_6/ 49\n",
      "In folder: 2111 \t\tTotal: 95128\n",
      "Processing folder datasets/cropped_seq_6/ 50\n",
      "In folder: 2156 \t\tTotal: 97284\n",
      "Processing folder datasets/cropped_seq_6/ 51\n",
      "In folder: 2232 \t\tTotal: 99516\n",
      "Processing folder datasets/cropped_seq_6/ 52\n",
      "In folder: 2145 \t\tTotal: 101661\n",
      "Processing folder datasets/cropped_seq_6/ 53\n",
      "In folder: 2053 \t\tTotal: 103714\n",
      "Processing folder datasets/cropped_seq_6/ 54\n",
      "In folder: 1933 \t\tTotal: 105647\n"
     ]
    }
   ],
   "source": [
    "folders = sorted(os.listdir(in_f))\n",
    "X_sum = 0\n",
    "# -------------------------------------------------------\n",
    "for i in range(0,55):\n",
    "    print(\"Processing folder\", in_f, folders[i])\n",
    "    \n",
    "    X_tmp,y_tmp = dt.loadSeqToNPA(in_f+folders[i]+\"/\",3,3)\n",
    "    X_tmp = np.rot90(X_tmp,k=i%4,axes=(2,3))     # rotate the image\n",
    "    y_tmp = np.rot90(y_tmp,k=i%4,axes=(2,3))     # rotate the image\n",
    "    \n",
    "    np.save(in_f+\"loaded/\"+str(i)+\"_X\",X_tmp)\n",
    "    np.save(in_f+\"loaded/\"+str(i)+\"_y\",y_tmp)\n",
    "    \n",
    "    X_sum += X_tmp.shape[0]\n",
    "    \n",
    "    print(\"In folder:\",X_tmp.shape[0],\"\\t\\tTotal:\",X_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = \"datasets/cropped_seq_6/loaded/\"\n",
    "out_f = \"datasets/dataset_extrapolation/full/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (105647, 3, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "X = dt.concatNPA(in_f,range(55),\"_X.npy\")\n",
    "np.save(out_f+\"X\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (105647, 3, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "y = dt.concatNPA(in_f, range(55),\"_y.npy\")\n",
    "np.save(out_f+\"y\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "out_f = \"datasets/dataset_extrapolation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check 1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8d8dd2b8a5ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# -------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# -------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 2212\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 2212\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "in_f = out_f+\"full/\"\n",
    "# -------------------------------------------------------\n",
    "X = np.load(in_f+\"X.npy\")\n",
    "y = np.load(in_f+\"y.npy\")\n",
    "print(\"check 1\")\n",
    "# -------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "print(\"check 2\")\n",
    "# -------------------------------------------------------\n",
    "np.save(out_f+\"X_train_tmp\",X_train)\n",
    "np.save(out_f+\"y_train_tmp\",y_train)\n",
    "np.save(out_f+\"X_test\",X_test)\n",
    "np.save(out_f+\"y_test\",y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================\n",
    "\n",
    "================================================================\n",
    "\n",
    "================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35526, 1, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "name = \"y_val\"\n",
    "in_f = \"datasets/dataset_interpolation_96/\"\n",
    "out_f = \"datasets/dataset_interpolation_96/tmp/\"\n",
    "y = np.load(in_f+ name + \".npy\")\n",
    "y = np.expand_dims(y,1)\n",
    "print(y.shape)\n",
    "np.save(out_f+name, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/interpolation/X_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-747ff7bed592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/interpolation/X_train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/interpolation/y_train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# np.save(\"datasets/interpolation/X_test\",Xtest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# np.save(\"datasets/interpolation/y_test\",ytest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/interpolation/X_train.npy'"
     ]
    }
   ],
   "source": [
    "np.save(\"datasets/interpolation/X_train\",Xtrain)\n",
    "np.save(\"datasets/interpolation/y_train\",ytrain)\n",
    "np.save(\"datasets/interpolation/X_test\",Xtest)\n",
    "np.save(\"datasets/interpolation/y_test\",ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateSave(in_f, l, name, suf):\n",
    "    # -------------------------------------------------------\n",
    "    for i in l:\n",
    "        X_tmp = np.load(in_f+str(i)+name+suf)\n",
    "        X_tmp = np.rot90(X_tmp,k=4-i%4, axes=(1,2))\n",
    "        np.save(in_f+str(i)+name, X_tmp)\n",
    "    # -------------------------------------------------------\n",
    "rotateSave(in_f, range(55), \"_y\", \".npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making dataset smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes the training part of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142101, 1, 96, 96)\n",
      "(35526, 1, 96, 96)\n",
      "(44407, 1, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "# Xtrain = np.load(\"datasets/dataset_interpolation_96/X_train.npy\")\n",
    "ytrain = np.load(\"datasets/dataset_interpolation_96/y_train.npy\")\n",
    "print(ytrain.shape)\n",
    "ytrain = np.load(\"datasets/dataset_interpolation_96/y_val.npy\")\n",
    "print(ytrain.shape)\n",
    "ytrain = np.load(\"datasets/dataset_interpolation_96/y_test.npy\")\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149872, 96, 96)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtrash, ytrain, ytrash = train_test_split(Xtrain, ytrain, test_size=0.13, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/dataset_interpolation_96/smaller/X_train\",Xtrain)\n",
    "np.save(\"datasets/dataset_interpolation_96/smaller/y_train\",ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes the test part of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtest = np.load(\"datasets/dataset_interpolation_96/X_test.npy\")\n",
    "ytest = np.load(\"datasets/dataset_interpolation_96/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49958, 96, 96)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest, Xtrash, ytest, ytrash = train_test_split(Xtest, ytest, test_size=0.13, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datasets/dataset_interpolation_96/smaller/X_test\",Xtest)\n",
    "np.save(\"datasets/dataset_interpolation_96/smaller/y_test\",ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
