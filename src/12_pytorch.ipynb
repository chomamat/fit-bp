{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "b3FAMmp61N9O",
    "outputId": "6c6ebf5b-ec30-4c48-9f5b-16398fcc03d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.0.0 from https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl (532.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 532.5MB 30kB/s \n",
      "\u001b[31mfastai 1.0.50.post1 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Found existing installation: torch 1.0.1.post2\n",
      "    Uninstalling torch-1.0.1.post2:\n",
      "      Successfully uninstalled torch-1.0.1.post2\n",
      "Successfully installed torch-1.0.0\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "total 949904\n",
      "-rw------- 1 root root      2875 Apr  1 12:15 _dataset_tools.py\n",
      "drwx------ 3 root root      4096 Apr  1 12:15 gdrive\n",
      "-rw------- 1 root root      2481 Apr  1 12:15 _my_tools.py\n",
      "drwxr-xr-x 1 root root      4096 Mar 27 20:26 sample_data\n",
      "-rw------- 1 root root 129687680 Apr  1 12:15 X_test.npy\n",
      "-rw------- 1 root root 518750336 Apr  1 12:15 X_train.npy\n",
      "-rw------- 1 root root  64843904 Apr  1 12:15 y_test.npy\n",
      "-rw------- 1 root root 259375232 Apr  1 12:15 y_train.npy\n"
     ]
    }
   ],
   "source": [
    "!pip3 install https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torchvision\n",
    "!pip3 install torchsummary\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!cp gdrive/My\\ Drive/x64/*.npy .\n",
    "!cp gdrive/My\\ Drive/*.py .\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QG3xCwCI1Mfg",
    "outputId": "7b8eda5a-d647-4216-ed7a-df00a1ed4763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import summary\n",
    "import tools._my_tools as mt\n",
    "import tools._torch_tools as tt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)\n",
    "# X_train, y_train, X_test, y_test = mt.loadData(\"\",'float16',channels_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScRT-TqfAAyg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 96, 96]              38\n",
      "             PReLU-2            [-1, 2, 96, 96]               1\n",
      "            Conv2d-3            [-1, 2, 96, 96]              38\n",
      "             PReLU-4            [-1, 2, 96, 96]               1\n",
      "            Conv2d-5           [-1, 32, 96, 96]             608\n",
      "             PReLU-6           [-1, 32, 96, 96]               1\n",
      "             PReLU-7           [-1, 32, 96, 96]               1\n",
      "             PReLU-8           [-1, 32, 96, 96]               1\n",
      "             PReLU-9           [-1, 32, 96, 96]               1\n",
      "            PReLU-10           [-1, 32, 96, 96]               1\n",
      "            PReLU-11           [-1, 32, 96, 96]               1\n",
      "            PReLU-12           [-1, 32, 96, 96]               1\n",
      "            PReLU-13           [-1, 32, 96, 96]               1\n",
      "            PReLU-14           [-1, 32, 96, 96]               1\n",
      "            PReLU-15           [-1, 32, 96, 96]               1\n",
      "            PReLU-16           [-1, 32, 96, 96]               1\n",
      "            PReLU-17           [-1, 32, 96, 96]               1\n",
      "            PReLU-18           [-1, 32, 96, 96]               1\n",
      "        AvgPool2d-19           [-1, 32, 48, 48]               0\n",
      "           Conv2d-20           [-1, 32, 48, 48]           9,248\n",
      "            PReLU-21           [-1, 32, 48, 48]               1\n",
      "           Conv2d-22           [-1, 32, 48, 48]           9,248\n",
      "            PReLU-23           [-1, 32, 48, 48]               1\n",
      "           Conv2d-24           [-1, 64, 48, 48]          18,496\n",
      "            PReLU-25           [-1, 64, 48, 48]               1\n",
      "            PReLU-26           [-1, 64, 48, 48]               1\n",
      "            PReLU-27           [-1, 64, 48, 48]               1\n",
      "            PReLU-28           [-1, 64, 48, 48]               1\n",
      "            PReLU-29           [-1, 64, 48, 48]               1\n",
      "            PReLU-30           [-1, 64, 48, 48]               1\n",
      "            PReLU-31           [-1, 64, 48, 48]               1\n",
      "            PReLU-32           [-1, 64, 48, 48]               1\n",
      "            PReLU-33           [-1, 64, 48, 48]               1\n",
      "            PReLU-34           [-1, 64, 48, 48]               1\n",
      "            PReLU-35           [-1, 64, 48, 48]               1\n",
      "            PReLU-36           [-1, 64, 48, 48]               1\n",
      "            PReLU-37           [-1, 64, 48, 48]               1\n",
      "        AvgPool2d-38           [-1, 64, 24, 24]               0\n",
      "           Conv2d-39           [-1, 64, 24, 24]          36,928\n",
      "            PReLU-40           [-1, 64, 24, 24]               1\n",
      "           Conv2d-41           [-1, 64, 24, 24]          36,928\n",
      "            PReLU-42           [-1, 64, 24, 24]               1\n",
      "           Conv2d-43          [-1, 128, 24, 24]          73,856\n",
      "            PReLU-44          [-1, 128, 24, 24]               1\n",
      "            PReLU-45          [-1, 128, 24, 24]               1\n",
      "            PReLU-46          [-1, 128, 24, 24]               1\n",
      "            PReLU-47          [-1, 128, 24, 24]               1\n",
      "            PReLU-48          [-1, 128, 24, 24]               1\n",
      "            PReLU-49          [-1, 128, 24, 24]               1\n",
      "            PReLU-50          [-1, 128, 24, 24]               1\n",
      "            PReLU-51          [-1, 128, 24, 24]               1\n",
      "            PReLU-52          [-1, 128, 24, 24]               1\n",
      "            PReLU-53          [-1, 128, 24, 24]               1\n",
      "            PReLU-54          [-1, 128, 24, 24]               1\n",
      "            PReLU-55          [-1, 128, 24, 24]               1\n",
      "            PReLU-56          [-1, 128, 24, 24]               1\n",
      "        AvgPool2d-57          [-1, 128, 12, 12]               0\n",
      "           Conv2d-58          [-1, 128, 12, 12]         147,584\n",
      "            PReLU-59          [-1, 128, 12, 12]               1\n",
      "           Conv2d-60          [-1, 128, 12, 12]         147,584\n",
      "            PReLU-61          [-1, 128, 12, 12]               1\n",
      "           Conv2d-62          [-1, 256, 12, 12]         295,168\n",
      "            PReLU-63          [-1, 256, 12, 12]               1\n",
      "            PReLU-64          [-1, 256, 12, 12]               1\n",
      "            PReLU-65          [-1, 256, 12, 12]               1\n",
      "            PReLU-66          [-1, 256, 12, 12]               1\n",
      "            PReLU-67          [-1, 256, 12, 12]               1\n",
      "            PReLU-68          [-1, 256, 12, 12]               1\n",
      "            PReLU-69          [-1, 256, 12, 12]               1\n",
      "            PReLU-70          [-1, 256, 12, 12]               1\n",
      "            PReLU-71          [-1, 256, 12, 12]               1\n",
      "            PReLU-72          [-1, 256, 12, 12]               1\n",
      "            PReLU-73          [-1, 256, 12, 12]               1\n",
      "            PReLU-74          [-1, 256, 12, 12]               1\n",
      "            PReLU-75          [-1, 256, 12, 12]               1\n",
      "        AvgPool2d-76            [-1, 256, 6, 6]               0\n",
      "           Conv2d-77            [-1, 256, 6, 6]         590,080\n",
      "            PReLU-78            [-1, 256, 6, 6]               1\n",
      "           Conv2d-79            [-1, 256, 6, 6]         590,080\n",
      "            PReLU-80            [-1, 256, 6, 6]               1\n",
      "           Conv2d-81            [-1, 256, 6, 6]         590,080\n",
      "            PReLU-82            [-1, 256, 6, 6]               1\n",
      "            PReLU-83            [-1, 256, 6, 6]               1\n",
      "            PReLU-84            [-1, 256, 6, 6]               1\n",
      "            PReLU-85            [-1, 256, 6, 6]               1\n",
      "            PReLU-86            [-1, 256, 6, 6]               1\n",
      "            PReLU-87            [-1, 256, 6, 6]               1\n",
      "            PReLU-88            [-1, 256, 6, 6]               1\n",
      "            PReLU-89            [-1, 256, 6, 6]               1\n",
      "            PReLU-90            [-1, 256, 6, 6]               1\n",
      "            PReLU-91            [-1, 256, 6, 6]               1\n",
      "            PReLU-92            [-1, 256, 6, 6]               1\n",
      "            PReLU-93            [-1, 256, 6, 6]               1\n",
      "            PReLU-94            [-1, 256, 6, 6]               1\n",
      "         Upsample-95          [-1, 256, 12, 12]               0\n",
      "         Upsample-96          [-1, 256, 12, 12]               0\n",
      "         Upsample-97          [-1, 256, 12, 12]               0\n",
      "         Upsample-98          [-1, 256, 12, 12]               0\n",
      "         Upsample-99          [-1, 256, 12, 12]               0\n",
      "          Conv2d-100          [-1, 256, 12, 12]         590,080\n",
      "           PReLU-101          [-1, 256, 12, 12]               1\n",
      "           PReLU-102          [-1, 256, 12, 12]               1\n",
      "           PReLU-103          [-1, 256, 12, 12]               1\n",
      "           PReLU-104          [-1, 256, 12, 12]               1\n",
      "           PReLU-105          [-1, 256, 12, 12]               1\n",
      "           PReLU-106          [-1, 256, 12, 12]               1\n",
      "           PReLU-107          [-1, 256, 12, 12]               1\n",
      "           PReLU-108          [-1, 256, 12, 12]               1\n",
      "           PReLU-109          [-1, 256, 12, 12]               1\n",
      "           PReLU-110          [-1, 256, 12, 12]               1\n",
      "           PReLU-111          [-1, 256, 12, 12]               1\n",
      "           PReLU-112          [-1, 256, 12, 12]               1\n",
      "           PReLU-113          [-1, 256, 12, 12]               1\n",
      "          Conv2d-114          [-1, 256, 12, 12]         590,080\n",
      "           PReLU-115          [-1, 256, 12, 12]               1\n",
      "          Conv2d-116          [-1, 256, 12, 12]         590,080\n",
      "           PReLU-117          [-1, 256, 12, 12]               1\n",
      "          Conv2d-118          [-1, 128, 12, 12]         295,040\n",
      "           PReLU-119          [-1, 128, 12, 12]               1\n",
      "           PReLU-120          [-1, 128, 12, 12]               1\n",
      "           PReLU-121          [-1, 128, 12, 12]               1\n",
      "           PReLU-122          [-1, 128, 12, 12]               1\n",
      "           PReLU-123          [-1, 128, 12, 12]               1\n",
      "           PReLU-124          [-1, 128, 12, 12]               1\n",
      "           PReLU-125          [-1, 128, 12, 12]               1\n",
      "           PReLU-126          [-1, 128, 12, 12]               1\n",
      "           PReLU-127          [-1, 128, 12, 12]               1\n",
      "           PReLU-128          [-1, 128, 12, 12]               1\n",
      "           PReLU-129          [-1, 128, 12, 12]               1\n",
      "           PReLU-130          [-1, 128, 12, 12]               1\n",
      "           PReLU-131          [-1, 128, 12, 12]               1\n",
      "        Upsample-132          [-1, 128, 24, 24]               0\n",
      "        Upsample-133          [-1, 128, 24, 24]               0\n",
      "        Upsample-134          [-1, 128, 24, 24]               0\n",
      "        Upsample-135          [-1, 128, 24, 24]               0\n",
      "        Upsample-136          [-1, 128, 24, 24]               0\n",
      "          Conv2d-137          [-1, 128, 24, 24]         147,584\n",
      "           PReLU-138          [-1, 128, 24, 24]               1\n",
      "           PReLU-139          [-1, 128, 24, 24]               1\n",
      "           PReLU-140          [-1, 128, 24, 24]               1\n",
      "           PReLU-141          [-1, 128, 24, 24]               1\n",
      "           PReLU-142          [-1, 128, 24, 24]               1\n",
      "           PReLU-143          [-1, 128, 24, 24]               1\n",
      "           PReLU-144          [-1, 128, 24, 24]               1\n",
      "           PReLU-145          [-1, 128, 24, 24]               1\n",
      "           PReLU-146          [-1, 128, 24, 24]               1\n",
      "           PReLU-147          [-1, 128, 24, 24]               1\n",
      "           PReLU-148          [-1, 128, 24, 24]               1\n",
      "           PReLU-149          [-1, 128, 24, 24]               1\n",
      "           PReLU-150          [-1, 128, 24, 24]               1\n",
      "          Conv2d-151          [-1, 128, 24, 24]         147,584\n",
      "           PReLU-152          [-1, 128, 24, 24]               1\n",
      "          Conv2d-153          [-1, 128, 24, 24]         147,584\n",
      "           PReLU-154          [-1, 128, 24, 24]               1\n",
      "          Conv2d-155           [-1, 64, 24, 24]          73,792\n",
      "           PReLU-156           [-1, 64, 24, 24]               1\n",
      "           PReLU-157           [-1, 64, 24, 24]               1\n",
      "           PReLU-158           [-1, 64, 24, 24]               1\n",
      "           PReLU-159           [-1, 64, 24, 24]               1\n",
      "           PReLU-160           [-1, 64, 24, 24]               1\n",
      "           PReLU-161           [-1, 64, 24, 24]               1\n",
      "           PReLU-162           [-1, 64, 24, 24]               1\n",
      "           PReLU-163           [-1, 64, 24, 24]               1\n",
      "           PReLU-164           [-1, 64, 24, 24]               1\n",
      "           PReLU-165           [-1, 64, 24, 24]               1\n",
      "           PReLU-166           [-1, 64, 24, 24]               1\n",
      "           PReLU-167           [-1, 64, 24, 24]               1\n",
      "           PReLU-168           [-1, 64, 24, 24]               1\n",
      "        Upsample-169           [-1, 64, 48, 48]               0\n",
      "        Upsample-170           [-1, 64, 48, 48]               0\n",
      "        Upsample-171           [-1, 64, 48, 48]               0\n",
      "        Upsample-172           [-1, 64, 48, 48]               0\n",
      "        Upsample-173           [-1, 64, 48, 48]               0\n",
      "          Conv2d-174           [-1, 64, 48, 48]          36,928\n",
      "           PReLU-175           [-1, 64, 48, 48]               1\n",
      "           PReLU-176           [-1, 64, 48, 48]               1\n",
      "           PReLU-177           [-1, 64, 48, 48]               1\n",
      "           PReLU-178           [-1, 64, 48, 48]               1\n",
      "           PReLU-179           [-1, 64, 48, 48]               1\n",
      "           PReLU-180           [-1, 64, 48, 48]               1\n",
      "           PReLU-181           [-1, 64, 48, 48]               1\n",
      "           PReLU-182           [-1, 64, 48, 48]               1\n",
      "           PReLU-183           [-1, 64, 48, 48]               1\n",
      "           PReLU-184           [-1, 64, 48, 48]               1\n",
      "           PReLU-185           [-1, 64, 48, 48]               1\n",
      "           PReLU-186           [-1, 64, 48, 48]               1\n",
      "           PReLU-187           [-1, 64, 48, 48]               1\n",
      "          Conv2d-188           [-1, 64, 48, 48]          36,928\n",
      "           PReLU-189           [-1, 64, 48, 48]               1\n",
      "          Conv2d-190           [-1, 64, 48, 48]          36,928\n",
      "           PReLU-191           [-1, 64, 48, 48]               1\n",
      "          Conv2d-192           [-1, 32, 48, 48]          18,464\n",
      "           PReLU-193           [-1, 32, 48, 48]               1\n",
      "           PReLU-194           [-1, 32, 48, 48]               1\n",
      "           PReLU-195           [-1, 32, 48, 48]               1\n",
      "           PReLU-196           [-1, 32, 48, 48]               1\n",
      "           PReLU-197           [-1, 32, 48, 48]               1\n",
      "           PReLU-198           [-1, 32, 48, 48]               1\n",
      "           PReLU-199           [-1, 32, 48, 48]               1\n",
      "           PReLU-200           [-1, 32, 48, 48]               1\n",
      "           PReLU-201           [-1, 32, 48, 48]               1\n",
      "           PReLU-202           [-1, 32, 48, 48]               1\n",
      "           PReLU-203           [-1, 32, 48, 48]               1\n",
      "           PReLU-204           [-1, 32, 48, 48]               1\n",
      "           PReLU-205           [-1, 32, 48, 48]               1\n",
      "        Upsample-206           [-1, 32, 96, 96]               0\n",
      "        Upsample-207           [-1, 32, 96, 96]               0\n",
      "        Upsample-208           [-1, 32, 96, 96]               0\n",
      "        Upsample-209           [-1, 32, 96, 96]               0\n",
      "        Upsample-210           [-1, 32, 96, 96]               0\n",
      "          Conv2d-211           [-1, 32, 96, 96]           9,248\n",
      "           PReLU-212           [-1, 32, 96, 96]               1\n",
      "           PReLU-213           [-1, 32, 96, 96]               1\n",
      "           PReLU-214           [-1, 32, 96, 96]               1\n",
      "           PReLU-215           [-1, 32, 96, 96]               1\n",
      "           PReLU-216           [-1, 32, 96, 96]               1\n",
      "           PReLU-217           [-1, 32, 96, 96]               1\n",
      "           PReLU-218           [-1, 32, 96, 96]               1\n",
      "           PReLU-219           [-1, 32, 96, 96]               1\n",
      "           PReLU-220           [-1, 32, 96, 96]               1\n",
      "           PReLU-221           [-1, 32, 96, 96]               1\n",
      "           PReLU-222           [-1, 32, 96, 96]               1\n",
      "           PReLU-223           [-1, 32, 96, 96]               1\n",
      "           PReLU-224           [-1, 32, 96, 96]               1\n",
      "          Conv2d-225           [-1, 32, 96, 96]           9,248\n",
      "           PReLU-226           [-1, 32, 96, 96]               1\n",
      "          Conv2d-227           [-1, 32, 96, 96]           9,248\n",
      "           PReLU-228           [-1, 32, 96, 96]               1\n",
      "          Conv2d-229            [-1, 1, 96, 96]             289\n",
      "================================================================\n",
      "Total params: 5,285,243\n",
      "Trainable params: 5,285,243\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 176.77\n",
      "Params size (MB): 20.16\n",
      "Estimated Total Size (MB): 197.00\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.KERNEL_SIZE = 31\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "        self.conv_setup = {\n",
    "            'kernel' : (3,3),\n",
    "            'stride' : (1,1),\n",
    "            'padding' : 1,\n",
    "            'activation' : self.activation\n",
    "        }\n",
    "        self.pooling_setup = {\n",
    "            'kernel_size' : (2,2),\n",
    "            'stride' : (2,2)\n",
    "        }\n",
    "        self.upsample_setup = {\n",
    "            'scale_factor' : 2,\n",
    "            'mode' : 'bilinear',\n",
    "            'align_corners' : True\n",
    "        }\n",
    "\n",
    "        self.pooling_layer = nn.AvgPool2d(**self.pooling_setup)\n",
    "        self.upsample_layer = nn.Upsample(**self.upsample_setup)\n",
    "        \n",
    "        self.conv32 = self._convBlock(2, 32, **self.conv_setup)\n",
    "        self.conv64 = self._convBlock(32, 64, **self.conv_setup)\n",
    "        self.conv128 = self._convBlock(64, 128, **self.conv_setup)\n",
    "        self.conv256 = self._convBlock(128, 256, **self.conv_setup)\n",
    "        self.conv256_256 = self._convBlock(256, 256, **self.conv_setup)\n",
    "\n",
    "\n",
    "        self.upsample256 = self._upsampleBlock(self.upsample_layer, 256, 256, **self.conv_setup)\n",
    "        self.deconv128 = self._convBlock(256, 128, **self.conv_setup)\n",
    "        self.upsample128 = self._upsampleBlock(self.upsample_layer, 128, 128, **self.conv_setup)\n",
    "        self.deconv64 = self._convBlock(128, 64, **self.conv_setup)\n",
    "        self.upsample64 = self._upsampleBlock(self.upsample_layer, 64, 64, **self.conv_setup)\n",
    "        self.deconv32 = self._convBlock(64, 32, **self.conv_setup)\n",
    "        self.upsample32 = self._upsampleBlock(self.upsample_layer, 32, 32, **self.conv_setup)\n",
    "        self.deconv1 = self._convBlock(32, 1, kernel=(3,3), stride=(1,1), padding=1, activation=None)#**self.conv_setup)\n",
    "#         self.deconv1 = nn.Conv2d(32, 1, (3,3), (1,1), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x32 = self.conv32(x)\n",
    "        x32_p = self.pooling_layer(x32)\n",
    "        x64 = self.conv64(x32_p)\n",
    "        x64_p = self.pooling_layer(x64)\n",
    "        x128 = self.conv128(x64_p)\n",
    "        x128_p = self.pooling_layer(x128)\n",
    "        x256 = self.conv256(x128_p)\n",
    "        x256_p = self.pooling_layer(x256)\n",
    "\n",
    "        x = self.conv256_256(x256_p)\n",
    "\n",
    "        # expansion\n",
    "\n",
    "        x = self.upsample256(x)\n",
    "        x += x256\n",
    "        x = self.deconv128(x)\n",
    "\n",
    "        x = self.upsample128(x)\n",
    "        x += x128\n",
    "        x = self.deconv64(x)\n",
    "\n",
    "        x = self.upsample64(x)\n",
    "        x += x64\n",
    "        x = self.deconv32(x)\n",
    "        \n",
    "        x = self.upsample32(x)\n",
    "        x += x32\n",
    "        x = self.deconv1(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def _convBlock(in_channels, out_channels, kernel, stride, padding, activation):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), nn.PReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), nn.PReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel, stride, padding)\n",
    "        )\n",
    "        if activation is not None:\n",
    "            net = nn.Sequential(net, activation)\n",
    "        return net\n",
    "    @staticmethod\n",
    "    def _upsampleBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation):\n",
    "        return nn.Sequential(\n",
    "            upsample,\n",
    "            nn.Conv2d(in_channels, out_channels, kernel, stride, padding), activation\n",
    "        )\n",
    "\n",
    "# model = Model()\n",
    "# model.to(device)\n",
    "# if device == torch.device(\"cpu\"):\n",
    "#     print(summary(model, (2,96,96)))\n",
    "# else:\n",
    "#     print(summary(model.cuda(), (2,96,96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "training = tt.Training(model, device, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "hOrq8Ntbj_EH",
    "outputId": "f11f39c9-ec2b-4dfe-de6e-b40bc3394046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== HYPERPARAMETERS ======\n",
      "batch_size = 128\n",
      "epochs = 6\n",
      "device cuda:0\n",
      "=============================\n",
      "===> Epoch[0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[0](12/494): Loss: 0.0327\tETA 0:08:56\tEpoch Loss: 0.0497\n",
      "\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    training.fit(64, 4, val=True)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nFinished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z8oKILPqAdMl",
    "outputId": "ac2b7ed4-1d0b-495c-f7ff-f1f80f813db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': [], 'val': []}\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3bsVh5Y9HQt5"
   },
   "outputs": [],
   "source": [
    "torch.save(A.state_dict(), \"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "3802eg6ZT0fX",
    "outputId": "f7647c41-45a3-4f85-a713-68a4f9418b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: 00.png (stored 0%)\n",
      "  adding: 01.png (stored 0%)\n",
      "  adding: 02.png (deflated 1%)\n",
      "  adding: 03.png (deflated 1%)\n",
      "  adding: 04.png (stored 0%)\n",
      "  adding: 05.png (deflated 2%)\n",
      "  adding: 06.png (deflated 3%)\n",
      "  adding: 07.png (stored 0%)\n",
      "  adding: 08.png (stored 0%)\n",
      "  adding: 09.png (deflated 4%)\n"
     ]
    }
   ],
   "source": [
    "!zip fig.zip *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ln-QM5j6IoDl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "12_pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
