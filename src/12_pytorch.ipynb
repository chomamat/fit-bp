{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "b3FAMmp61N9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "9189cf43-c9d8-47d1-d941-0931e83ad8c2"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip3 install torchsummary\n",
        "!pip3 install tensorboardX\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp gdrive/My\\ Drive/x64/*.npy .\n",
        "!cp gdrive/My\\ Drive/*.py .\n",
        "!ls -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.0 from https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.8.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.6\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "total 949904\n",
            "drwxr-xr-x 3 root root      4096 Mar 28 10:34 data\n",
            "-rw------- 1 root root      2875 Mar 28 15:24 _dataset_tools.py\n",
            "drwx------ 3 root root      4096 Mar 28 11:07 gdrive\n",
            "-rw------- 1 root root      2481 Mar 28 15:24 _my_tools.py\n",
            "drwxr-xr-x 2 root root      4096 Mar 28 15:19 __pycache__\n",
            "drwxr-xr-x 1 root root      4096 Mar  8 17:26 sample_data\n",
            "-rw------- 1 root root 129687680 Mar 28 15:23 X_test.npy\n",
            "-rw------- 1 root root 518750336 Mar 28 15:24 X_train.npy\n",
            "-rw------- 1 root root  64843904 Mar 28 15:24 y_test.npy\n",
            "-rw------- 1 root root 259375232 Mar 28 15:24 y_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QG3xCwCI1Mfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "79968c1c-9f99-4397-a609-12341c5e9b6e"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from torchsummary import summary\n",
        "\n",
        "import _my_tools as mt\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device is\", device)\n",
        "# X_train, y_train, X_test, y_test = mt.loadData(\"\",'float16',channels_last=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device is cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ScRT-TqfAAyg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.KERNEL_SIZE = 31\n",
        "        self.activation = nn.ReLU()\n",
        "        \n",
        "        self.conv_setup = {\n",
        "            'kernel' : (3,3),\n",
        "            'stride' : (1,1),\n",
        "            'padding' : 1,\n",
        "            'activation' : self.activation\n",
        "        }\n",
        "        self.pooling_setup = {\n",
        "            'kernel_size' : (2,2),\n",
        "            'stride' : (2,2)\n",
        "        }\n",
        "        self.upsample_setup = {\n",
        "            'scale_factor' : 2,\n",
        "            'mode' : 'bilinear',\n",
        "            'align_corners' : True\n",
        "        }\n",
        "\n",
        "        self.pooling_layer = nn.AvgPool2d(**self.pooling_setup)\n",
        "        self.upsample_layer = nn.Upsample(**self.upsample_setup)\n",
        "        \n",
        "        self.conv32 = self._convBlock(2, 32, **self.conv_setup)\n",
        "        self.conv64 = self._convBlock(32, 64, **self.conv_setup)\n",
        "        self.conv128 = self._convBlock(64, 128, **self.conv_setup)\n",
        "        self.conv256 = self._convBlock(128, 256, **self.conv_setup)\n",
        "        self.conv256_256 = self._convBlock(256, 256, **self.conv_setup)\n",
        "\n",
        "\n",
        "        self.upsample256 = self._upsampleBlock(self.upsample_layer, 256, 256, **self.conv_setup)\n",
        "        self.deconv128 = self._convBlock(256, 128, **self.conv_setup)\n",
        "        self.upsample128 = self._upsampleBlock(self.upsample_layer, 128, 128, **self.conv_setup)\n",
        "        self.deconv64 = self._convBlock(128, 64, **self.conv_setup)\n",
        "        self.upsample64 = self._upsampleBlock(self.upsample_layer, 64, 64, **self.conv_setup)\n",
        "        self.deconv32 = self._convBlock(64, 32, **self.conv_setup)\n",
        "        self.upsample32 = self._upsampleBlock(self.upsample_layer, 32, 32, **self.conv_setup)\n",
        "        self.deconv1 = self._convBlock(32, 1, **self.conv_setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x32 = self.conv32(x)\n",
        "        x32_p = self.pooling_layer(x32)\n",
        "        x64 = self.conv64(x32_p)\n",
        "        x64_p = self.pooling_layer(x64)\n",
        "        x128 = self.conv128(x64_p)\n",
        "        x128_p = self.pooling_layer(x128)\n",
        "        x256 = self.conv256(x128_p)\n",
        "        x256_p = self.pooling_layer(x256)\n",
        "\n",
        "        x = self.conv256_256(x256_p)\n",
        "\n",
        "        # expansion\n",
        "\n",
        "        x = self.upsample256(x)\n",
        "        x += x256\n",
        "        x = self.deconv128(x)\n",
        "\n",
        "        x = self.upsample128(x)\n",
        "        x += x128\n",
        "        x = self.deconv64(x)\n",
        "\n",
        "        x = self.upsample64(x)\n",
        "        x += x64\n",
        "        x = self.deconv32(x)\n",
        "        \n",
        "        x = self.upsample32(x)\n",
        "        x += x32\n",
        "        x = self.deconv1(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    @staticmethod\n",
        "    def _convBlock(in_channels, out_channels, kernel, stride, padding, activation):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), activation,\n",
        "            nn.Conv2d(in_channels, in_channels, kernel, stride, padding), activation,\n",
        "            nn.Conv2d(in_channels, out_channels, kernel, stride, padding), activation\n",
        "        )\n",
        "    @staticmethod\n",
        "    def _upsampleBlock(upsample, in_channels, out_channels, kernel, stride, padding, activation):\n",
        "        return nn.Sequential(\n",
        "            upsample,\n",
        "            nn.Conv2d(in_channels, out_channels, kernel, stride, padding), activation\n",
        "        )\n",
        "\n",
        "model = Model()\n",
        "# print(model)\n",
        "print(summary(model.cuda(), (2,64,64)))\n",
        "    \n",
        "# --------------------------------------------------------------------------------------------------\n",
        "\n",
        "def getLossOptimizer(net, learning_rate=0.001):\n",
        "    loss_function = nn.L1Loss()\n",
        "    optimizer = optim.Adamax(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    return (loss_function, optimizer)\n",
        "\n",
        "def getBatch(X, y, offset, batch_size, device):\n",
        "    input = torch.tensor( X[ offset:offset + batch_size ], dtype=torch.float)\n",
        "    target = torch.tensor( y[ offset:offset + batch_size ], dtype=torch.float)\n",
        "    return input.to(device), target.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOrq8Ntbj_EH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "3de89e9d-de17-4e03-972f-f46c514b2ba6"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def fit(model, device, X, y, batch_size, n_epochs, val=None):\n",
        "    \n",
        "    #Print all of the hyperparameters of the training iteration:\n",
        "    print(\"====== HYPERPARAMETERS ======\")\n",
        "    print(\"batch_size =\", batch_size)\n",
        "    print(\"epochs =\", n_epochs)\n",
        "#     print(\"X shape -\", X.shape)\n",
        "#     print(\"y shape -\", y.shape)\n",
        "    print(\"=\" * 29)\n",
        "    \n",
        "    assert X.shape[0] == y.shape[0]\n",
        "    assert X.shape[2:4] == y.shape[2:4]\n",
        "    \n",
        "    model.to(device)\n",
        "    loss_function, optimizer = getLossOptimizer(model)\n",
        "    n_batch = X.shape[0] // batch_size\n",
        "    \n",
        "    training_start_T = time.time()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"===> Epoch[{}]\".format(epoch), end='', flush=True)\n",
        "        for it in range(n_batch):\n",
        "            input, target = getBatch(X, y, it, batch_size, device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(input)\n",
        "            loss = loss_function(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_val = loss.item()\n",
        "            epoch_loss += loss_val\n",
        "\n",
        "            print(\"\\r\", end='')\n",
        "            print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\\tETA:{}\\tEpoch Loss: {:.4f}\"\n",
        "                  .format(epoch, it, n_batch, loss_val,\"00:43\", epoch_loss / (it+1)), end='', flush=True)\n",
        "            \n",
        "        print(\"Epoch[{}] finished.\".format(epoch))\n",
        "        \n",
        "        if val is tuple:\n",
        "            X_val, y_val = val\n",
        "            assert X_val.shape[0] == y_val.shape[0]\n",
        "            \n",
        "            total_loss_val = 0\n",
        "            n_batch_val = X_val.shape[0] // batch_size\n",
        "            \n",
        "            print(\"Validating on {} samples.\".format(n_batch_val * batch_size))\n",
        "            \n",
        "            for it in range(n_batch_val):\n",
        "                input, target = getBatch(X_val, y_val, it, batch_size, device)\n",
        "                \n",
        "                output = model(input)\n",
        "                loss_val = loss_function(output, target)\n",
        "                total_loss_val += loss_val.data[0]\n",
        "                \n",
        "            print(\"Validation loss = {:.4f}\".format(total_loss_val / n_batch_val))\n",
        "            \n",
        "        elif val is not None:\n",
        "            print(\"Cannot validate. Tuple (X_val, y_val) expected.\")\n",
        "\n",
        "\n",
        "\n",
        "fit(model, device, X_train, y_train, 128, 2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== HYPERPARAMETERS ======\n",
            "batch_size = 128\n",
            "epochs = 2\n",
            "=============================\n",
            "===> Epoch[0]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===> Epoch[0](8/494): Loss: 0.0902\tETA:00:43\tEpoch Loss: 0.0899"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-29d8930c2f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-29d8930c2f05>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, device, X, y, batch_size, n_epochs, val)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Z8oKILPqAdMl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MCrnl_xE1Mfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff213292-86a9-40f8-f5a1-d6b15e2a5f72"
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 170450944/170498071 [00:41<00:00, 4770928.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yBx2alsz1Mfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "d8b2f24a-d06b-4b75-f308-5df81b88be88"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAACWCAYAAACfIIJIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/2r0qZiTt/2tAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "truck  frog   cat  bird\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mxItm3K_1Mf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "444746b2-e9ed-47fe-f023-93834ecaf89b"
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(summary(net.cuda(), (3,32,32)))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             456\n",
            "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
            "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
            "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
            "            Linear-5                  [-1, 120]          48,120\n",
            "            Linear-6                   [-1, 84]          10,164\n",
            "            Linear-7                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Azb5sKxe1Mf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "edd4a67d-7fc0-44e2-ef58-1d1e6cc80dd5"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.251\n",
            "[1,  4000] loss: 1.912\n",
            "[1,  6000] loss: 1.686\n",
            "[1,  8000] loss: 1.571\n",
            "[1, 10000] loss: 1.517\n",
            "[1, 12000] loss: 1.437\n",
            "[2,  2000] loss: 1.385\n",
            "[2,  4000] loss: 1.362\n",
            "[2,  6000] loss: 1.344\n",
            "[2,  8000] loss: 1.306\n",
            "[2, 10000] loss: 1.250\n",
            "[2, 12000] loss: 1.248\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5wo2dwD4ZdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "8e6aa153-f118-4c0f-e96f-07e13348a1dd"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "fUQS_grs1Mf_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ]
    },
    {
      "metadata": {
        "id": "2yWY24iY1MgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# make_dot was moved to https://github.com/szagoruyko/pytorchviz\n",
        "from torchviz import make_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGU8M1Xv1MgE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First play"
      ]
    },
    {
      "metadata": {
        "id": "EnuxdGJ71MgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "738339ca-8ded-4cf9-e518-a2a7c2d9a6d9"
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "# print(summary(net, (1,32,32)))\n",
        "print(summary(net.cuda(), (1,28,28)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             156\n",
            "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
            "            Linear-3                  [-1, 120]          48,120\n",
            "            Linear-4                   [-1, 84]          10,164\n",
            "            Linear-5                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.29\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PepTivcE1MgK",
        "colab_type": "code",
        "colab": {},
        "outputId": "82d5a5ad-b990-4def-d4e2-1bb86b05c99f"
      },
      "cell_type": "code",
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8J3HitWP1MgO",
        "colab_type": "code",
        "colab": {},
        "outputId": "81f9b9fd-8e09-45c3-c347-1cc2cd57fc37"
      },
      "cell_type": "code",
      "source": [
        "input = torch.tensor(X_train[0:2], dtype=torch.float)\n",
        "out = net(input)\n",
        "target = torch.tensor(y_train[0:2], dtype=torch.float)\n",
        "print(out)\n",
        "print(target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 4.3331,  1.9793,  2.6187,  0.6244, -0.2817, -2.9674, -1.3366,  2.2282,\n",
            "          2.5437, -0.4990],\n",
            "        [ 5.5507,  1.4275,  2.2521, -2.5445, -2.0108, -4.9094, -0.9845,  3.9079,\n",
            "          0.0534,  1.6705]], grad_fn=<AddmmBackward>)\n",
            "tensor([[5.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pvqBrsa51MgS",
        "colab_type": "code",
        "colab": {},
        "outputId": "90c3a8fb-a82c-4617-ca88-6db1a19752b3"
      },
      "cell_type": "code",
      "source": [
        "net.zero_grad()\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "None\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.1084,  0.1247, -0.0140,  0.0410,  0.0010,  0.0325])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N7REtrTq1MgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "n_b = 16\n",
        "\n",
        "for i in range(0,X_train.shape[0],n_b):\n",
        "    input = torch.tensor(X_train[i:i+n_b], dtype=torch.float)\n",
        "    target = torch.tensor(y_train[i:i+n_b], dtype=torch.float)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = net(input)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U_RzvX6D1Mgc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JqHIgL1I1Mgh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape([-1,1,28,28])\n",
        "y_train = y_train.reshape([-1,1])\n",
        "# a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRR8KZ6-1Mgl",
        "colab_type": "code",
        "colab": {},
        "outputId": "7290412a-88ae-46c9-ada7-c52b9bdbf6a9"
      },
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           3,  18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154,\n",
              "         170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "         253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253,\n",
              "         253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253,\n",
              "         253, 205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154,\n",
              "         253,  90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139,\n",
              "         253, 190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
              "         190, 253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          35, 241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          39, 148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "         221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253,\n",
              "         253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253,\n",
              "         253, 195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244,\n",
              "         133,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "lFUTyEdR1Mgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}