{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools._dataset_tools as dt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "root = \"examples/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts images in `examples/dataset/in/` to grayscale saves them in `examples/dataset/mono/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = root + \"in/\"\n",
    "out_f = root + \"mono/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)\n",
    "    \n",
    "images = sorted(os.listdir(in_f))\n",
    "for i in images:\n",
    "    img = cv.imread(in_f+i, cv.IMREAD_UNCHANGED)\n",
    "    cv.imwrite(out_f+i, dt.convert2Mono(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for the interpolation task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Cropping\n",
    "All of the grayscale radar images from folder `examples/dataset/mono/` are taken and squares of size $96\\times96$ are cropped from them with a stride of size $48$. The cropped squares are saved in `examples/dataset/cropped/` in folder according to the square's coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = root + \"mono/\"\n",
    "out_f = root + \"cropped/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)\n",
    "\n",
    "for f in range(55):\n",
    "    if not os.path.exists(out_f+str(f).zfill(2)):\n",
    "        os.mkdir(out_f+str(f).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.cropFolder(in_f,out_f,96,48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Triplets Finding\n",
    "All images from every folder of `examples/dataset/cropped/` are taken, and images that have more than $95\\%$ of the area without precipitation or have only precipitation of level $1$ (on scale $0-15$) are deleted. The previous images may also be removed so that there are in the end always left three consecutive images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = root + \"cropped/\"\n",
    "for folder in sorted(os.listdir(in_f)):\n",
    "    dt.findSequence(in_f+folder+\"/\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading to NumPy Array\n",
    "\n",
    "Load all files in every folder to X, y numpy arrays by folders. Rotations are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_f = root + \"cropped/\"\n",
    "out_f = in_f + \"loaded/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)\n",
    "\n",
    "folders = sorted(os.listdir(in_f))\n",
    "X_sum = 0\n",
    "# -------------------------------------------------------\n",
    "for i in range(0,55):\n",
    "    print(\"Processing folder\", in_f, folders[i])\n",
    "    \n",
    "    X_tmp,y_tmp = dt.loadToNPA(in_f+folders[i]+\"/\")\n",
    "    \n",
    "    if len(X_tmp) == 0:\n",
    "        continue\n",
    "    \n",
    "    X_tmp = np.rot90(X_tmp,k=i%4,axes=(2,3))          # rotate the image\n",
    "    y_tmp = np.rot90(y_tmp,k=i%4,axes=(1,2))          # rotate the image. Axis (1,2) because there is no channel information in y_tmp yet.\n",
    "    \n",
    "    np.save(out_f+str(i)+\"_X\",X_tmp)\n",
    "    np.save(out_f+str(i)+\"_y\",y_tmp)\n",
    "    \n",
    "    X_sum += X_tmp.shape[0]\n",
    "    \n",
    "    print(\"In folder:\",X_tmp.shape[0],\"\\t\\tTotal:\",X_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = root + \"cropped/loaded/\"\n",
    "out_f = root + \"cropped/full/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)\n",
    "\n",
    "X = dt.concatNPA(in_f,range(55),\"_X.npy\")\n",
    "np.save(out_f+\"X\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = root + \"cropped/loaded/\"\n",
    "out_f = root + \"cropped/full/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)\n",
    "\n",
    "y = dt.concatNPA(in_f, range(55),\"_y.npy\")\n",
    "y = np.expand_dims(y,1)                     # expand the dimensions so it fits with x\n",
    "print(\"Final shape:\",y.shape)\n",
    "np.save(out_f+\"y\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset\n",
    "The test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# -------------------------------------------------------\n",
    "in_f = root + \"cropped/full/\"\n",
    "out_f = root\n",
    "\n",
    "X = np.load(in_f+\"X.npy\")\n",
    "y = np.load(in_f+\"y.npy\")\n",
    "# -------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "# -------------------------------------------------------\n",
    "np.save(out_f+\"X_train_tmp\",X_train)\n",
    "np.save(out_f+\"y_train_tmp\",y_train)\n",
    "np.save(out_f+\"X_test\",X_test)\n",
    "np.save(out_f+\"y_test\",y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# -------------------------------------------------------\n",
    "in_f = root\n",
    "out_f = root\n",
    "\n",
    "X = np.load(in_f+\"X_train_tmp.npy\")\n",
    "y = np.load(in_f+\"y_train_tmp.npy\")\n",
    "# -------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "# -------------------------------------------------------\n",
    "np.save(out_f+\"X_train\",X_train)\n",
    "np.save(out_f+\"y_train\",y_train)\n",
    "np.save(out_f+\"X_val\",X_val)\n",
    "np.save(out_f+\"y_val\",y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for the extrapolation task\n",
    "The process is analogical to the one for the interpolation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = root + \"mono/\"\n",
    "out_f = root + \"cropped_6/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)\n",
    "\n",
    "for f in range(55):\n",
    "    if not os.path.exists(out_f+str(f).zfill(2)):\n",
    "        os.mkdir(out_f+str(f).zfill(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop $96\\times 96$ patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.cropFolder(in_f,out_f,96,48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove images with no information and group them to sequences of $6$ consecutive images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_f = root + \"cropped_6/\"\n",
    "\n",
    "for folder in sorted(os.listdir(in_f)):\n",
    "    dt.findSequence(in_f+folder+\"/\", 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images from each folder in $\\{00,01,\\dots,54\\}$ to a separate numpy arrays X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_f = root + \"cropped_6/\"\n",
    "out_f = in_f + \"loaded/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)\n",
    "\n",
    "folders = sorted(os.listdir(in_f))\n",
    "X_sum = 0\n",
    "# -------------------------------------------------------\n",
    "for i in range(0,55):\n",
    "    print(\"Processing folder\", in_f, folders[i])\n",
    "    \n",
    "    X_tmp,y_tmp = dt.loadSeqToNPA(in_f+folders[i]+\"/\",3,3)\n",
    "    if len(X_tmp) == 0:\n",
    "        continue\n",
    "    \n",
    "    X_tmp = np.rot90(X_tmp,k=i%4,axes=(2,3))     # rotate the image\n",
    "    y_tmp = np.rot90(y_tmp,k=i%4,axes=(2,3))     # rotate the image\n",
    "    \n",
    "    np.save(out_f+str(i)+\"_X\",X_tmp)\n",
    "    np.save(out_f+str(i)+\"_y\",y_tmp)\n",
    "    \n",
    "    X_sum += X_tmp.shape[0]\n",
    "    \n",
    "    print(\"In folder:\",X_tmp.shape[0],\"\\t\\tTotal:\",X_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f = root + \"cropped_6/loaded/\"\n",
    "out_f = root + \"full/\"\n",
    "if not os.path.exists(out_f):\n",
    "    os.makedirs(out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.concatNPA(in_f,range(55),\"_X.npy\")\n",
    "np.save(out_f+\"X\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dt.concatNPA(in_f, range(55),\"_y.npy\")\n",
    "np.save(out_f+\"y\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "in_f = root + \"full/\"\n",
    "out_f = root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.load(in_f+\"X.npy\")\n",
    "y = np.load(in_f+\"y.npy\")\n",
    "# -------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "# -------------------------------------------------------\n",
    "np.save(out_f+\"X_train_tmp\",X_train)\n",
    "np.save(out_f+\"y_train_tmp\",y_train)\n",
    "np.save(out_f+\"X_test\",X_test)\n",
    "np.save(out_f+\"y_test\",y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(out_f+\"X_train_tmp.npy\")\n",
    "y = np.load(out_f+\"y_train_tmp.npy\")\n",
    "# -------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "# -------------------------------------------------------\n",
    "np.save(out_f+\"X_train\",X_train)\n",
    "np.save(out_f+\"y_train\",y_train)\n",
    "np.save(out_f+\"X_val\",X_val)\n",
    "np.save(out_f+\"y_val\",y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
